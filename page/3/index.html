<!DOCTYPE html>
<html lang="en">
  <head>
	<meta name="generator" content="Hugo 0.102.1" />
    
      <title>
        David Just —
        A technology website
      </title>
    
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta
  name="description"
  content="A technology website"
/>
<meta
  name="keywords"
  content=""
/>
<meta name="robots" content="noodp" />
<link rel="canonical" href="/" />




<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'Page(\u0022David Just\u0022)', 'auto');
ga('send', 'pageview');

</script>




<link rel="stylesheet" href="/assets/style.css" />


<link
  rel="apple-touch-icon-precomposed"
  sizes="144x144"
  href="/img/apple-touch-icon-144-precomposed.png"
/>
<link rel="shortcut icon" href="/img/favicon.png" />


<link href="/assets/fonts/Inter-Italic.woff2" rel="preload" type="font/woff2" as="font" crossorigin="">
<link href="/assets/fonts/Inter-Regular.woff2" rel="preload" type="font/woff2" as="font" crossorigin="">
<link href="/assets/fonts/Inter-Medium.woff2" rel="preload" type="font/woff2" as="font" crossorigin="">
<link href="/assets/fonts/Inter-MediumItalic.woff2" rel="preload" type="font/woff2" as="font" crossorigin="">
<link href="/assets/fonts/Inter-Bold.woff2" rel="preload" type="font/woff2" as="font" crossorigin="">
<link href="/assets/fonts/Inter-BoldItalic.woff2" rel="preload" type="font/woff2" as="font" crossorigin="">


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="David Just"/>
<meta name="twitter:description" content=""/>



<meta property="og:title" content="David Just" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="/" /><meta property="og:site_name" content="David Just" />




<link rel="alternate" type="application/rss+xml" href="/index.xml" title="David Just" />



  </head>
  <body class="dark-theme">
    <div class="container">
      <header class="header">
  <span class="header__inner">
    <a
  href="/"
  class="logo"
  style="text-decoration: none;"
>
  
    <span class="logo__mark">PS C:\Users\Dave></span>
    <span class="logo__text">Invoke-Blog</span>
    <span class="logo__cursor"></span>
  
</a>

    <span class="header__right">
      
        <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
            
          <li><a href="/about">About <img src=""/> 
          </a></li>        
          
        
      
            
          <li><a href="https://github.com/djust270">My Github <img src=""/> 
          </a></li>        
          
        
      
            
          <li><a href="/index.xml"> <img src="/rss%20%28Custom%29.png"/> 
          </a></li>        
          
        
      
            
          <li><a href="/search">Search <img src=""/> 
          </a></li>        
          
        
      
      
      
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About</a></li>
      
    
      
        <li><a href="https://github.com/djust270">My Github</a></li>
      
    
      
        <li><a href="/index.xml"></a></li>
      
    
      
        <li><a href="/search">Search</a></li>
      
    
  </ul>
</nav>

        <span class="menu-trigger">
          <svg xmlns="" viewBox="0 0 24 24">
            <path d="M0 0h24v24H0z" fill="none" />
            <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z" />
          </svg>
        </span>
      
      <span class="theme-toggle">
        <svg
  class="theme-toggler"
  width="24"
  height="24"
  viewBox="0 0 48 48"
  fill="none"
  xmlns="http://www.w3.org/2000/svg"
>
  <path
    d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"
  />
</svg>

      </span>
    </span>
  </span>
</header>


      <div class="content">
        
  
  

  
  
    
  
  

  

  <div class="posts">
    
    <div class="post on-list">
      <h1 class="post-title"><a href="/post/intune-for-macos-configure-profiles/">Intune for macOS Part 2 - Setup BYOD enrollment and Configure macOS Profiles</a></h1>
      <div class="post-meta">
        
          <span class="post-date">
            April 19, 2022

          </span>

          
        

        
          <span class="post-author">— Written by David Just</span>
        

        
      </div>

      
        <span class="post-tags">
          
            <a href="/tags/o365/">#O365</a>&nbsp;
          
            <a href="/tags/intune/">#Intune</a>&nbsp;
          
            <a href="/tags/macos/">#macOS</a>&nbsp;
          
        </span>
      

      
        <figure class="post-cover">
  
    <img src="/post/intune-for-macos-configure-profiles/mac.jpeg" alt="Intune for macOS Part 2 - Setup BYOD enrollment and Configure macOS Profiles"/>
  

  
</figure>

      

      <div class="post-content">
        
          
            Setup BYOD Enrollment In part 1, we explored how to setup a macOS virtual machine for testing. Now lets look at actually configuring Intune. The first thing we need to do is get an Apple MDM push certificate.
Navigate to endpoint.microsoft.com &lt; Devices &lt; Enroll Devices &lt; Apple Enrollment. Download the CSR. Follow the link “Create your MDM Push Certificate” Sign into your Apple ID (or create one if you do not have one) Click create certificate.
          
        
      </div>
      
        <div><a class="read-more button" href="/post/intune-for-macos-configure-profiles/">Read more →</a></div>
      
    </div>
    
    <div class="post on-list">
      <h1 class="post-title"><a href="/post/intune-install-software-with-winget/">Intune Deploy Software with WinGet</a></h1>
      <div class="post-meta">
        
          <span class="post-date">
            March 8, 2022

          </span>

          
        

        
          <span class="post-author">— Written by David Just</span>
        

        
      </div>

      
        <span class="post-tags">
          
            <a href="/tags/o365/">#O365</a>&nbsp;
          
            <a href="/tags/intune/">#Intune</a>&nbsp;
          
            <a href="/tags/winget/">#WinGet</a>&nbsp;
          
        </span>
      

      
        <figure class="post-cover">
  
    <img src="/post/intune-install-software-with-winget/winget.png" alt="Intune Deploy Software with WinGet"/>
  

  
</figure>

      

      <div class="post-content">
        
          
            Ever since the WinGet package manager was announced, I wanted to find ways to leverage the package manager to simplify deploying software to endpoints. After doing some research and testing, I found that WinGet was unfortunately not designed to be run in SYSTEM context. It was designed to be run under a user account. There is an open issue on GitHub currently and many admins, myself included, would really like WinGet to be designed with enterprise use in mind.
          
        
      </div>
      
        <div><a class="read-more button" href="/post/intune-install-software-with-winget/">Read more →</a></div>
      
    </div>
    
    <div class="post on-list">
      <h1 class="post-title"><a href="/post/intune-for-macos-configure-macos-vm/">Configuring Intune for macOS part 1 - Setup a macOS VM</a></h1>
      <div class="post-meta">
        
          <span class="post-date">
            January 2, 2022

          </span>

          
        

        
          <span class="post-author">— Written by David Just</span>
        

        
      </div>

      
        <span class="post-tags">
          
            <a href="/tags/o365/">#O365</a>&nbsp;
          
            <a href="/tags/intune/">#Intune</a>&nbsp;
          
            <a href="/tags/macos/">#macOS</a>&nbsp;
          
        </span>
      

      
        <figure class="post-cover">
  
    <img src="/post/intune-for-macos-configure-macos-vm/macdark.png" alt="Configuring Intune for macOS part 1 - Setup a macOS VM"/>
  

  
</figure>

      

      <div class="post-content">
        
          
            Premise
One of my clients has an Apple only environment. The client was previously managed with Jamf. Jamf is a great MDM platform for Apple devices and works really well however there are some downsides. First, the cost of Jamf is quite high, also while Jamf does support M365 condtional access and SSO with M365, it requires a bit more configuration than Intune does. My client was already paying for Enterprise mobility and Security licensing through M365 with Defender ATP for Endpoint so why not take advantage of the included Intune licensing?
          
        
      </div>
      
        <div><a class="read-more button" href="/post/intune-for-macos-configure-macos-vm/">Read more →</a></div>
      
    </div>
    
    <div class="post on-list">
      <h1 class="post-title"><a href="/post/use-powershell-to-get-the-weather-report/">PowerShell Project - Get the Weather report</a></h1>
      <div class="post-meta">
        
          <span class="post-date">
            October 26, 2021

          </span>

          
        

        
          <span class="post-author">— Written by David Just</span>
        

        
      </div>

      
        <span class="post-tags">
          
            <a href="/tags/powershell/">#PowerShell</a>&nbsp;
          
            <a href="/tags/restapi/">#restAPI</a>&nbsp;
          
        </span>
      

      

      <div class="post-content">
        
          
            I thought it would be a fun project to create a PowerShell function which would get the Weather forecast for a specified location.
I started searching online for free Weather REST APIs which I could query for the forecast. I found api.weather.gov which has a completely free and open REST API with complete documentation API Web Service (weather.gov). Checking the documentation, the REST endpoint to query the forecast is https://api.weather.gov/gridpoints/{office}/{gridX},{grid Y}/forecast.
          
        
      </div>
      
        <div><a class="read-more button" href="/post/use-powershell-to-get-the-weather-report/">Read more →</a></div>
      
    </div>
    
    <div class="post on-list">
      <h1 class="post-title"><a href="/post/o365-license-report-with-friendly-names/">Export O365 User License Report with friendly names</a></h1>
      <div class="post-meta">
        
          <span class="post-date">
            April 11, 2021

          </span>

          
        

        
          <span class="post-author">— Written by David Just</span>
        

        
      </div>

      
        <span class="post-tags">
          
            <a href="/tags/powershell/">#PowerShell</a>&nbsp;
          
            <a href="/tags/intune/">#Intune</a>&nbsp;
          
        </span>
      

      

      <div class="post-content">
        
          
            I was recently tasked with exporting a report for a client that detailed all users, their location and license assignment in Office 365. I knew the best way to get the job done was by writing a PowerShell script.
I did a quick search online and found lots of examples, however all the examples I found were using the deprecated &ldquo;Microsoft Online&rdquo; / MSOL PS module. I wanted to use the Azure AD module instead so I played around a bit to get the output I wanted.
          
        
      </div>
      
        <div><a class="read-more button" href="/post/o365-license-report-with-friendly-names/">Read more →</a></div>
      
    </div>
    
    <div class="pagination">
  <div class="pagination__buttons">
    
      <span class="button previous">
        <a href="/page/2/">
          <span class="button__icon">←</span>
          <span class="button__text">Newer posts</span>
        </a>
      </span>
    
    
      <span class="button next">
        <a href="/page/4/">
          <span class="button__text">Older posts</span>
          <span class="button__icon">→</span>
        </a>
      </span>
    
  </div>
</div>

  </div>

      </div>

      
        <footer class="footer">
  davidjust.com © 2022     
  <div class="footer__inner">    
  </div>
  <div class="footer__right">     
    
    <a href="mailto:david@davidjust.com" target="_blank" rel="noopener noreferrer me" title="email">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 21" fill="none" stroke="currentColor" stroke-width="2"
width="40" height="40"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path>
    <polyline points="22,6 12,13 2,6"></polyline>    
</svg>   
    </a>     
    
    <a href="https://twitter.com/DavidJu14353759" target="_blank" rel="noopener noreferrer me" title="twitter">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
width="40" height="40"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z">
    </path>
</svg>   
    </a>     
     
  </div>     
</footer>
<script src="/assets/main.js"></script>
<script src="/assets/prism.js"></script>


<script>
    window.store = {
        
        
        
        
        "\/tags\/azure-ad\/": {
            
            "title": "Azure AD",
            "tags": [],
            "content": "", 
            "url": "\/tags\/azure-ad\/"
        },
        
        
        
        "\/": {
            
            "title": "David Just",
            "tags": [],
            "content": "", 
            "url": "\/"
        },
        
        
        
        "\/post\/m365-report-tools\/": {
            
            "title": "Introducing the M365 Report Tools PowerShell Module",
            "tags": ["O365","Microsoft Graph","Azure AD","PowerShell",],
            "content": "The Why I often find the need to gather and extract data from various areas M365 for auditing or for project planning. I had the idea of putting together a PowerShell module containing wrapper functions for some of the most common reports I and colleagues ask for. I wanted to make the commands easy to discover and easy to use. I would like to introduce the M365.Report.Tools PowerShell module!\nWhat can it do? To quote myself M365.Report.Tools is: \u0026ldquo;A PowerShell Module with tools built for gathering data and creating reports on various areas of M365 services. This module is designed with ease of use with several baked in custom reports and the ability to export any built in Admin center usage report. Reports can be easily exported to CSV file, Excel workbook(s), or JSON.\nThis module leverages the Microsoft Graph PowerShell SDK, Exchange Online PowerShell, SharePoint Online PowerShell and ImportExcel. The majority of commands use the Graph SDK and seamlessly handle the permission scope and connection to Graph for you.\u0026rdquo;\nI tried to use the Microsoft Graph SDK as much as possible, however there are still places where Graph doesnt have much reach, such as inside Exchange Online and SharePoint Online. For more information on working with the Graph SDK, see here\r.\nI plan on continuing development on this module and will add additional functions with more reports. Here are the commands so far:\nGet-M365GroupReport\rReport of every group including group type and source of authority.\nGet-M365MailboxReport\rReport of every mailbox including details such as mailbox size. Use -IncludeMailboxSize to report on each mailbox current size.\nGet-M365MGUserPrincipalGroupMembership\rGet every group a user is a member of\nGet-M365SharePointSiteSummary\rSummarize all Sharepoint sites including details for each site such as storage usage and sharing capabilites.\nGet-M365SSOEnterpriseApps\rReturn all AzureAD enterprise applications with SAML SSO integration.\nGet-M365TeamsChannelReport\rReturn a list of every channel in each Team including members.\nGet-M365TeamsReport\rReturn a list of all Teams and Team members.\nGet-M365TenantLicenseReport\rReturn a list of all licenses in a tenant including current utilization.\nGet-M365UsageReport\rReturn any of the baked in Admin Center period usage reports for easy export.\nGet-M365UserLicenseReport\rList every license assigned to every user\nGet-M365UserReport\rGet a summary report for all user accounts in an M365 tenant.\nGet-M365AdminReportSettings\rGet the current Admin Report setting for Admin Center period usage reports.\nSet-M365AdminReportSettings\rChange the admin report settings to hide or show names in Admin Center usage reports.\nSimply pipe any of these commands to Export-CSV or Export-Excel for easy export. This should make it easy for anyone with minimal PowerShell experience to use.\nIf you have an suggestions or comments, feel free to leave a comment here or drop me a line over on Github.\n", 
            "url": "\/post\/m365-report-tools\/"
        },
        
        
        
        "\/tags\/microsoft-graph\/": {
            
            "title": "Microsoft Graph",
            "tags": [],
            "content": "", 
            "url": "\/tags\/microsoft-graph\/"
        },
        
        
        
        "\/tags\/o365\/": {
            
            "title": "O365",
            "tags": [],
            "content": "", 
            "url": "\/tags\/o365\/"
        },
        
        
        
        "\/post\/": {
            
            "title": "Posts",
            "tags": [],
            "content": "", 
            "url": "\/post\/"
        },
        
        
        
        "\/tags\/powershell\/": {
            
            "title": "PowerShell",
            "tags": [],
            "content": "", 
            "url": "\/tags\/powershell\/"
        },
        
        
        
        "\/tags\/": {
            
            "title": "Tags",
            "tags": [],
            "content": "", 
            "url": "\/tags\/"
        },
        
        
        
        "\/tags\/intune\/": {
            
            "title": "Intune",
            "tags": [],
            "content": "", 
            "url": "\/tags\/intune\/"
        },
        
        
        
        "\/post\/intune-endpoint-tools-powershell-module\/": {
            
            "title": "Intune Endpoint Tools PowerShell Module",
            "tags": ["O365","Intune","PowerShell","Windows",],
            "content": "I am proud to introduce the PowerShell module IntuneEndpointTools. This is the first PS module I have published to the PowerShell gallery\r.\nIntuneEndpointTools contains a set of tools for managing and diagnosing Intune MDM on Windows endpoints designed with Intune support staff in mind. Easily perform diagnostic / troubleshooting operations such as get the MDM diagnostic report, full diagnostic package, force a full sync to Intune, force reprocessing of assigned applications and more!\nCheck it out over on GitHub! https://github.com/djust270/IntuneEndpointTools\r", 
            "url": "\/post\/intune-endpoint-tools-powershell-module\/"
        },
        
        
        
        "\/tags\/windows\/": {
            
            "title": "Windows",
            "tags": [],
            "content": "", 
            "url": "\/tags\/windows\/"
        },
        
        
        
        "\/post\/keep-applications-updated-with-winget-and-proactive-remediations\/": {
            
            "title": "Keep Applications Updated with WinGet and Proactive Remediations",
            "tags": ["Windows","PowerShell","O365","Intune","WinGet",],
            "content": "They Why In a previous article\r, I demonstrated how to deploy applications to Intune using WinGet . I recieved a request to demonstrate how to use WinGet to update applications, and more importantly, how to run this on a schedule to keep applications updated. Since then, I found a really handy PowerShell wrapper module for WinGet called WinGetTools by Jeffrey Hicks\r. I made a small contribution to this module to allow it to work running under SYSTEM context.\nThe How First, we need to install the above mentioned module WingetTools. This module has commands for listing out, installing, upgrading, and uninstalling packages, including listing which packages have updates available!\nHead over to my Github repository and grab with Install-WingetTools.intunewin file\r. Upload to Intune as a Win32 app set to install as System. For the installation command use:\npowershell.exe -executionpolicy bypass -file Install-WingetTools.ps1 For the uninstall command:\npowershell.exe -command \u0026#34;Uninstall-Module -Name WingetTools\u0026#34; For detection, use the detection script here\rAs best practice always test new deployments with a pilot group. Go ahead and assign to this group. This can be user or devices, it does not matter.\nThe app deployment should look like this:\nNow that we have the pre-requisites out of the way, lets move onto the proactive remediation. If you are not familiar with proactive remediations, read up on it here\r.\nWe need a detection script and a remediation script. The detection script will detect any applications installed with updates available in the WinGet repository (minus any apps we blacklisted). Here is the script\r:\n\u0026lt;#\t.NOTES =========================================================================== Created with: SAPIEN Technologies, Inc., PowerShell Studio 2021 v5.8.195 Created on: 8/22/2022 3:08 PM Created by: David Just Website: davidjust.com Filename: WingetUpgrade-ProactiveDetection.ps1 =========================================================================== .DESCRIPTION Proactive Remediation detection script for applications with updates #\u0026gt; $Blacklisted = @( \u0026#39;Microsoft.Teams\u0026#39; \u0026#39;Microsoft.Office\u0026#39; \u0026#39;Microsoft.VC++2015-2022Redist-x64\u0026#39; ) Import-Module -Name WingetTools $AvailableUpdates = Get-WGInstalled | where-object { $_.id -notin $Blacklisted -and $_.update } if ($AvailableUpdates.count -gt 0) { \u0026#34;There are applications with Updates available\u0026#34; $AvailableUpdates | Select-Object -Property Name, ID, InstalledVersion, OnlineVersion exit 1 } else { \u0026#34;There are no apps to update\u0026#34; Exit 0 } Now for the remediation script\r:\n\u0026lt;#\t.NOTES =========================================================================== Created with: SAPIEN Technologies, Inc., PowerShell Studio 2021 v5.8.195 Created on: 8/22/2022 10:46 AM Created by: David Just Website: david.just.com Filename: WingetUpgrade-Remediation.ps1 =========================================================================== .DESCRIPTION A description of the file. #\u0026gt; function Write-Log($message) #Log script messages to temp directory { $LogMessage = ((Get-Date -Format \u0026#34;MM-dd-yy HH:MM:ss \u0026#34;) + $message) Out-File -InputObject $LogMessage -FilePath \u0026#34;$LogPath\\$Log\u0026#34; -Append -Encoding utf8 } $LogName = \u0026#39;WinGetPackageUpgrade\u0026#39; $LogDate = Get-Date -Format dd-MM-yy_HH-mm # go with the EU format day / month / year $Log = \u0026#34;$LogName-$LogDate.log\u0026#34; $LogPath = \u0026#34;$env:ProgramData\\Microsoft\\IntuneManagementExtension\\Logs\u0026#34; Import-Module WingetTools $WingetPath = Get-WGPath # Add any apps you do not wish to get updated here (for instance apps that auto-update). Use the Winget ID $Blacklisted = @( \u0026#39;Microsoft.Teams\u0026#39; \u0026#39;Microsoft.Office\u0026#39; \u0026#39;Microsoft.VC++2015-2022Redist-x64\u0026#39; ) $AvailableUpdates = Get-WGInstalled | where-object { $_.id -notin $Blacklisted -and $_.update } Write-Log -message \u0026#34;Packages with Updates Available:\u0026#34; $AvailableUpdates | select Name, Version | Out-File -FilePath \u0026#34;$logpath\\$Log\u0026#34; -Append -Encoding utf8 foreach ($App in $AvailableUpdates) # Invoke upgrade for each updatable app and log results { [void](Get-Process | Where-Object { $_.name -Like \u0026#34;*$App.Name*\u0026#34; } | Stop-Process -Force) $UpgradeRun = \u0026amp; $WingetPath upgrade --id $App.id -h --accept-package-agreements --accept-source-agreements $UpgradeRun | Out-File -FilePath \u0026#34;$logpath\\$log\u0026#34; -Append -Encoding utf8 $Status = [bool]($UpgradeRun | select-string -SimpleMatch \u0026#34;Successfully installed\u0026#34;) if ($Status -eq $true) { $Success += $App } else { $Failed += $App } } if ($Success.count -gt 0) { Write-Log -message \u0026#34;Successful Upgraded the following:\u0026#34; $Success | Out-File -FilePath \u0026#34;$logpath\\$log\u0026#34; -Append -Encoding utf8 \u0026#34;Sucessfully Updated the following apps:`n{0}\u0026#34; -f $($Success | Select-Object -Property name) } if ($Failed.count -gt 0) { Write-Log -message \u0026#34;Failed to Upgrade the following:\u0026#34; $Failed | Out-File -FilePath \u0026#34;$logpath\\$log\u0026#34; -Append -Encoding utf8 } Create a new Proactive Remediation deployment by going to Reports \u0026lt; Endpoint Analytics \u0026lt; Proactive Remediations [direct link]\r.\nGive the script package a descriptive name, such as “Winget Update Apps”. Upload the detection and remediations scripts. Run in 64-bit and do not run with user credentials Select your desired schedule. To test, I set this to run hourly, but daily or weekly would probably be better. Assign to your pilot group. This may take awhile to feed back results. When looking at the proactive remediation results, add the columns “Pre-remediation detection output” and “Post-remediation detection output” to see the output from the scripts.\nAnd thats it. Now you can keep applications updated with Intune and Proactive remediations.\nIf you do not want to use a proactive remediaiton this script\rwill create a scheduled task on the endpoint to run the upgrade remediation.\n", 
            "url": "\/post\/keep-applications-updated-with-winget-and-proactive-remediations\/"
        },
        
        
        
        "\/tags\/winget\/": {
            
            "title": "WinGet",
            "tags": [],
            "content": "", 
            "url": "\/tags\/winget\/"
        },
        
        
        
        "\/tags\/teams\/": {
            
            "title": "Teams",
            "tags": [],
            "content": "", 
            "url": "\/tags\/teams\/"
        },
        
        
        
        "\/post\/update-business-voice-to-teams-phone-licenses\/": {
            
            "title": "Update Business Voice to Teams Phone Licenses",
            "tags": ["O365","PowerShell","Teams","Azure AD","Microsoft Graph",],
            "content": "Microsoft has announced the retirement of Business Voice licensing\r. If your tenant is still using Business Voice with Calling Plan or Business Voice without Calling Plan, you will need to switch to the new equivalent Teams Phone plan.\nIf you take a look at the Microsoft doc linked above, there are examples for how to update the licenses on bulk, however it is baffling Microsoft chose to demonstrate using the Azure AD PowerShell module, when the licensing portion of that module is slated to be retired as of today (6/30). I went ahead and created a script utilizing the Microsoft Graph API to update the licenses in bulk.\nFirst, as a precaution, connect to Microsoft Teams with PowerShell and export a list of all users and their assigned numbers. If at any time the voice license feature is unassigned for a user, their phone number assigment will be removed immediately. Don\u0026rsquo;t ask me how I know.\n# As a precaution, backup all users phone number assignments Connect-MicrosoftTeams Get-CsOnlineUser | where LineUri | select Displayname, UserPrincipalName, DialPlan, @{ N = \u0026#34;Line\u0026#34;; e = { $_.lineuri -replace \u0026#39;tel:\u0026#39;, \u0026#39;\u0026#39; } } | export-Csv TeamsUsers.csv -NoTypeInformation Next we need to identify the license sku to remove and the sku to add in place of the old sku. Log into Azure AD and check your current licensed products. Use the table here to find the SkuPartID (center column) https://docs.microsoft.com/en-us/azure/active-directory/enterprise-users/licensing-service-plan-reference\rIn my example, I will replace Business Voice with Calling Plan, with Teams Phone with Calling Plan and Microsoft Teams Audio Conferencing with dial-out to USA/CAN\n# Replace with appropriate sku names $OldSku = \u0026#34;BUSINESS_VOICE_MED2_TELCO\u0026#34; $NewSku = \u0026#34;MCOTEAMS_ESSENTIALS\u0026#34;, \u0026#34;MCOMEETBASIC\u0026#34; Now we need to connect to Microsoft Graph and gather our tenants license info\n# Get necessary permission scopes $perms = \u0026#39;User.Read.All\u0026#39;, \u0026#39;User.ReadWrite.All\u0026#39;, \u0026#39;Directory.Read.All\u0026#39; Connect-MgGraph -Scopes $perms Select-MgProfile beta $Skus = Get-MgSubscribedSku # Get all skus in the tenant $Users = Get-MGUser -All # Get all user accounts $OldVoiceSku = $skus | where { $_.skupartnumber -eq \u0026#34;$OldSku\u0026#34; } $NewVoiceSku = foreach ($Product in $NewSkus){ $s = $skus | where { $_.skupartnumber -like \u0026#34;$Product\u0026#34; } @{ SkuID = $s.SkuId } } Finally, we need to process our users, gather their current license assignment, filter for the users who need updated, then update the license assignment.\n$i = 0 # Increment variable foreach ($user in $Users) # Gather license assigments for all users { Write-Progress -Activity \u0026#34;Processing User License details\u0026#34; -Status \u0026#34;Working on $($user.displayname)\u0026#34; -PercentComplete (($i / $Users.Count) * 100) $user.LicenseDetails = Get-MgUserLicenseDetail -UserId $user.id Start-Sleep -Milliseconds 200 $i++ } $NeedsUpdated = $Users | where { $_.LicenseDetails.SkuPartNumber -like $OldSku } foreach ($u in $NeedsUpdated) { \u0026#34;Updating License assignment for {0}\u0026#34; -f $u.UserPrincipalName Set-MgUserLicense -UserId $u.id -AddLicenses $NewVoiceSku -RemoveLicenses @($OldVoiceSku.SkuId) #Add new license and remove old Start-Sleep -Milliseconds 200 } Finally as a check, lets make sure our users still have their phone assigments.\nGet-CsOnlineUser | select name,userprincipalname,lineuri You should see no change if everything went according to plan. See the entire script on my github account https://github.com/djust270/Microsoft-Graph-PowerShell-SDK-Scripts/blob/main/Update-TeamsVoiceLicenses.ps1\r", 
            "url": "\/post\/update-business-voice-to-teams-phone-licenses\/"
        },
        
        
        
        "\/post\/eventid-1098-token-broker-operation-failed\/": {
            
            "title": "AAD Token Broker Issues",
            "tags": ["O365","Windows","AzureAD",],
            "content": "Problem signs Outlook refuses to load, or a sign in window loops, opening and closing quickly. Outlook refuses to connect or send / recieve mail. The Windows store refuses to open. These are the initial symptoms I have seen when the AAD token broker \u0026lsquo;breaks\u0026rsquo; for lack of a better term. Event ID 1098 will be logged repeatedly in the Microsoft-Windows-AAD/Operational event log.\nThe fix Microsoft has a couple troubleshooting articles on event 1098 Event 1098 Cannot Create New Profiles\rand Event 1098 Error 0xcaa5001c\r.\nI have found a surefire way to get this resolved is to do the following:\nSign out of the affected user account\nSign into a Local Admin account.\nNavigate to the affected users profile folder local appdata folder. Rename or delete the AAD Token Broker folder. For example: C:\\users*username*\\Appdata\\Local\\Packages\\Microsoft.AAD.BrokerPlugin_cw5n1h2txyewy\nIf the computer is AzureAD registered, delete the computer object from AzureAD. If the computer is AzureAD joined, disconnect from AzureAD, then delete the computer object from AzureAD (if it exists).\nReboot. Sign back into the affected users profile (reconnecting AzureAD if necessary)\nSign back into office apps.\nThe takeaway I have not found an adequete explanantion for this behavior or why it happens. Microsoft does detail AzureAD authentication on Windows using the PRT (primary refresh token) and how the plugins work at a high level https://docs.microsoft.com/en-us/azure/active-directory/devices/concept-primary-refresh-token\r. My best educated guess is the PRT or session keys somehow get corrupted and the automatic recovery process fails. Doing the above steps forces authentication as if this was a new device. If anyone has a better explanation, please let me know.\n", 
            "url": "\/post\/eventid-1098-token-broker-operation-failed\/"
        },
        
        
        
        "\/tags\/azuread\/": {
            
            "title": "AzureAD",
            "tags": [],
            "content": "", 
            "url": "\/tags\/azuread\/"
        },
        
        
        
        "\/post\/kb5014754-certificate-woes-intune-ndes-scep\/": {
            
            "title": "KB5014754 Certificate Authentication Woes with NDES\/SCEP and Intune",
            "tags": ["O365","Intune","Azure AD",],
            "content": "About 2 years ago, I configured NDES and SCEP for a client that was moving all of their workstations to AzureAD join only. NDES and SCEP work together to provide certificate enrollment for AzureAD only joined devices for authentication with Wi-Fi / VPN etc. This was the Microsoft techcommunity article\rI followed to get this configued.\nFast foward to May 2022, in typical Microsoft fashion, a patch\rwas released to fix a security vulnerability to \u0026ldquo;address an elevation of privilege vulnerability that can occur when the Kerberos Distribution Center (KDC) is servicing a certificate-based authentication request.\u0026rdquo; This patch completely broke certificate based authentication for my client. The NPS would log error 6273, \u0026ldquo;Authentication failed due to a user credentials mismatch\u0026rdquo;\nAccording to the KB, the new patches no longer allow \u0026ldquo;weak\u0026rdquo; certificate mapping. My SCEP profile in Intune requests a certificate based on the users UPN which is considered weak. At this time, there is no option in the SCEP profile that would work with the new strong certificate mapping requirement. The KB does mention manually mapping the X509IssuerSerialNumber of the issued certificate to the altSecurityIdentities attribute of the AD user object. My collegue found this article\rwhich describes the issue and links to a script to automate mapping the certificates to user objects. The provided script however assumes that you are working with certificates that were requested by the AD user / computer (probably based on a GPO). With NDES, a service account requests the certificate on behalf of the user. I just had to modify the script a little for my purposes.\nOriginal Code specifying requester property for certificate mapping\nforeach($cert in ($certs | Sort-Object -Property \u0026#39;RequestID\u0026#39; -Descending)){ $requester = $cert.\u0026#39;Request.RequesterName\u0026#39; $requesterSplit = $requester.Split(\u0026#34;\\\u0026#34;) $CN = $requesterSplit[1] $Domain = $requesterSplit[0] Here I just had to change the requester variable to $requester = $cert.CommonName , as the CommonName is the users UPN that the cert should be mapped to. Then I changed the $CN variable to $CN = $requester\nHere is a link to the entire script https://github.com/djust270/Intune-Scripts/blob/master/Invoke-ADCSCertMappingNDES.ps1\r. Just update the static definitions at the top of the script. Change $dryrun to $false once you are ready to run. I have this running as a scheduled task every 5 minutes for my client so any new certificates will get mapped to the user object in AD.\n", 
            "url": "\/post\/kb5014754-certificate-woes-intune-ndes-scep\/"
        },
        
        
        
        "\/post\/o365-license-report-microsoft-graph\/": {
            
            "title": "O365 License Report With Friendly Names Using The Microsoft Graph",
            "tags": ["O365","Microsoft Graph","Azure AD",],
            "content": "\rIn a previous article\r, I demonstrated how to export a license report for all users withe the \u0026lsquo;friendly\u0026rsquo; license names using the AzureAD PowerShell module.\nSince then, Microsoft has announced the coming retirement of the AzureAD API\r(and assocaiated PowerShell modules). You should be migrating all scripts over to using the Microsoft Graph PowerShell SDK\rHere I will provide a sample script to demonstrate how to export a license report for all users in Azure AD utilizing the Microsoft Graph. I you need a primer on the Graph, see my previous article Working with the Microsoft Graph PowerShell SDK\rWhen querying Graph for license information, you will be previded with the sku part number for each license instead of the \u0026ldquo;friendly name\u0026rdquo;. First I will demonstate creating a hash table to lookup the friendly name from the license sku part number :\n$FriendlyLicenses = @{ \u0026#39;O365_BUSINESS_ESSENTIALS\u0026#39;\t= \u0026#39;Office 365 Business Essentials\u0026#39; \u0026#39;O365_BUSINESS_PREMIUM\u0026#39;\t= \u0026#39;Office 365 Business Premium\u0026#39; \u0026#39;DESKLESSPACK\u0026#39;\t= \u0026#39;Office 365 (Plan K1)\u0026#39; \u0026#39;DESKLESSWOFFPACK\u0026#39;\t= \u0026#39;Office 365 (Plan K2)\u0026#39; \u0026#39;LITEPACK\u0026#39;\t= \u0026#39;Office 365 (Plan P1)\u0026#39; \u0026#39;EXCHANGESTANDARD\u0026#39;\t= \u0026#39;Office 365 Exchange Online Only\u0026#39; \u0026#39;STANDARDPACK\u0026#39;\t= \u0026#39;Enterprise Plan E1\u0026#39; \u0026#39;STANDARDWOFFPACK\u0026#39;\t= \u0026#39;Office 365 (Plan E2)\u0026#39; \u0026#39;ENTERPRISEPACK\u0026#39;\t= \u0026#39;Enterprise Plan E3\u0026#39; \u0026#39;ENTERPRISEPACKLRG\u0026#39;\t= \u0026#39;Enterprise Plan E3\u0026#39; \u0026#39;ENTERPRISEWITHSCAL\u0026#39;\t= \u0026#39;Enterprise Plan E4\u0026#39; \u0026#39;STANDARDPACK_STUDENT\u0026#39;\t= \u0026#39;Office 365 (Plan A1) for Students\u0026#39; \u0026#39;STANDARDWOFFPACKPACK_STUDENT\u0026#39;\t= \u0026#39;Office 365 (Plan A2) for Students\u0026#39; \u0026#39;ENTERPRISEPACK_STUDENT\u0026#39;\t= \u0026#39;Office 365 (Plan A3) for Students\u0026#39; \u0026#39;ENTERPRISEWITHSCAL_STUDENT\u0026#39;\t= \u0026#39;Office 365 (Plan A4) for Students\u0026#39; \u0026#39;STANDARDPACK_FACULTY\u0026#39;\t= \u0026#39;Office 365 (Plan A1) for Faculty\u0026#39; \u0026#39;STANDARDWOFFPACKPACK_FACULTY\u0026#39;\t= \u0026#39;Office 365 (Plan A2) for Faculty\u0026#39; \u0026#39;ENTERPRISEPACK_FACULTY\u0026#39;\t= \u0026#39;Office 365 (Plan A3) for Faculty\u0026#39; \u0026#39;ENTERPRISEWITHSCAL_FACULTY\u0026#39;\t= \u0026#39;Office 365 (Plan A4) for Faculty\u0026#39; \u0026#39;ENTERPRISEPACK_B_PILOT\u0026#39;\t= \u0026#39;Office 365 (Enterprise Preview)\u0026#39; \u0026#39;STANDARD_B_PILOT\u0026#39;\t= \u0026#39;Office 365 (Small Business Preview)\u0026#39; \u0026#39;VISIOCLIENT\u0026#39;\t= \u0026#39;Visio Pro Online\u0026#39; \u0026#39;POWER_BI_ADDON\u0026#39;\t= \u0026#39;Office 365 Power BI Addon\u0026#39; \u0026#39;POWER_BI_INDIVIDUAL_USE\u0026#39;\t= \u0026#39;Power BI Individual User\u0026#39; \u0026#39;POWER_BI_STANDALONE\u0026#39;\t= \u0026#39;Power BI Stand Alone\u0026#39; \u0026#39;POWER_BI_STANDARD\u0026#39;\t= \u0026#39;Power-BI Standard\u0026#39; \u0026#39;PROJECTESSENTIALS\u0026#39;\t= \u0026#39;Project Lite\u0026#39; \u0026#39;PROJECTCLIENT\u0026#39;\t= \u0026#39;Project Professional\u0026#39; \u0026#39;PROJECTONLINE_PLAN_1\u0026#39;\t= \u0026#39;Project Online\u0026#39; \u0026#39;PROJECTONLINE_PLAN_2\u0026#39;\t= \u0026#39;Project Online and PRO\u0026#39; \u0026#39;ProjectPremium\u0026#39;\t= \u0026#39;Project Online Premium\u0026#39; \u0026#39;ECAL_SERVICES\u0026#39;\t= \u0026#39;ECAL\u0026#39; \u0026#39;EMS\u0026#39;\t= \u0026#39;Enterprise Mobility Suite\u0026#39; \u0026#39;RIGHTSMANAGEMENT_ADHOC\u0026#39;\t= \u0026#39;Windows Azure Rights Management\u0026#39; \u0026#39;MCOMEETADV\u0026#39;\t= \u0026#39;PSTN conferencing\u0026#39; \u0026#39;SHAREPOINTSTORAGE\u0026#39;\t= \u0026#39;SharePoint storage\u0026#39; \u0026#39;PLANNERSTANDALONE\u0026#39;\t= \u0026#39;Planner Standalone\u0026#39; \u0026#39;CRMIUR\u0026#39;\t= \u0026#39;CMRIUR\u0026#39; \u0026#39;BI_AZURE_P1\u0026#39;\t= \u0026#39;Power BI Reporting and Analytics\u0026#39; \u0026#39;INTUNE_A\u0026#39;\t= \u0026#39;Windows Intune Plan A\u0026#39; \u0026#39;PROJECTWORKMANAGEMENT\u0026#39;\t= \u0026#39;Office 365 Planner Preview\u0026#39; \u0026#39;ATP_ENTERPRISE\u0026#39;\t= \u0026#39;Exchange Online Advanced Threat Protection\u0026#39; \u0026#39;EQUIVIO_ANALYTICS\u0026#39;\t= \u0026#39;Office 365 Advanced eDiscovery\u0026#39; \u0026#39;AAD_BASIC\u0026#39;\t= \u0026#39;Azure Active Directory Basic\u0026#39; \u0026#39;RMS_S_ENTERPRISE\u0026#39;\t= \u0026#39;Azure Active Directory Rights Management\u0026#39; \u0026#39;AAD_PREMIUM\u0026#39;\t= \u0026#39;Azure Active Directory Premium\u0026#39; \u0026#39;MFA_PREMIUM\u0026#39;\t= \u0026#39;Azure Multi-Factor Authentication\u0026#39; \u0026#39;STANDARDPACK_GOV\u0026#39;\t= \u0026#39;Microsoft Office 365 (Plan G1) for Government\u0026#39; \u0026#39;STANDARDWOFFPACK_GOV\u0026#39;\t= \u0026#39;Microsoft Office 365 (Plan G2) for Government\u0026#39; \u0026#39;ENTERPRISEPACK_GOV\u0026#39;\t= \u0026#39;Microsoft Office 365 (Plan G3) for Government\u0026#39; \u0026#39;ENTERPRISEWITHSCAL_GOV\u0026#39;\t= \u0026#39;Microsoft Office 365 (Plan G4) for Government\u0026#39; \u0026#39;DESKLESSPACK_GOV\u0026#39;\t= \u0026#39;Microsoft Office 365 (Plan K1) for Government\u0026#39; \u0026#39;ESKLESSWOFFPACK_GOV\u0026#39;\t= \u0026#39;Microsoft Office 365 (Plan K2) for Government\u0026#39; \u0026#39;EXCHANGESTANDARD_GOV\u0026#39;\t= \u0026#39;Microsoft Office 365 Exchange Online (Plan 1) only for Government\u0026#39; \u0026#39;EXCHANGEENTERPRISE_GOV\u0026#39;\t= \u0026#39;Microsoft Office 365 Exchange Online (Plan 2) only for Government\u0026#39; \u0026#39;SHAREPOINTDESKLESS_GOV\u0026#39;\t= \u0026#39;SharePoint Online Kiosk\u0026#39; \u0026#39;EXCHANGE_S_DESKLESS_GOV\u0026#39;\t= \u0026#39;Exchange Kiosk\u0026#39; \u0026#39;RMS_S_ENTERPRISE_GOV\u0026#39;\t= \u0026#39;Windows Azure Active Directory Rights Management\u0026#39; \u0026#39;OFFICESUBSCRIPTION_GOV\u0026#39;\t= \u0026#39;Office ProPlus\u0026#39; \u0026#39;MCOSTANDARD_GOV\u0026#39;\t= \u0026#39;Lync Plan 2G\u0026#39; \u0026#39;SHAREPOINTWAC_GOV\u0026#39;\t= \u0026#39;Office Online for Government\u0026#39; \u0026#39;SHAREPOINTENTERPRISE_GOV\u0026#39;\t= \u0026#39;SharePoint Plan 2G\u0026#39; \u0026#39;EXCHANGE_S_ENTERPRISE_GOV\u0026#39;\t= \u0026#39;Exchange Plan 2G\u0026#39; \u0026#39;EXCHANGE_S_ARCHIVE_ADDON_GOV\u0026#39;\t= \u0026#39;Exchange Online Archiving\u0026#39; \u0026#39;EXCHANGE_S_DESKLESS\u0026#39;\t= \u0026#39;Exchange Online Kiosk\u0026#39; \u0026#39;SHAREPOINTDESKLESS\u0026#39;\t= \u0026#39;SharePoint Online Kiosk\u0026#39; \u0026#39;SHAREPOINTWAC\u0026#39;\t= \u0026#39;Office Online\u0026#39; \u0026#39;YAMMER_ENTERPRISE\u0026#39;\t= \u0026#39;Yammer for the Starship Enterprise\u0026#39; \u0026#39;EXCHANGE_L_STANDARD\u0026#39;\t= \u0026#39;Exchange Online (Plan 1)\u0026#39; \u0026#39;MCOLITE\u0026#39;\t= \u0026#39;Lync Online (Plan 1)\u0026#39; \u0026#39;SHAREPOINTLITE\u0026#39;\t= \u0026#39;SharePoint Online (Plan 1)\u0026#39; \u0026#39;OFFICE_PRO_PLUS_SUBSCRIPTION_SMBIZ\u0026#39; = \u0026#39;Office ProPlus\u0026#39; \u0026#39;EXCHANGE_S_STANDARD_MIDMARKET\u0026#39;\t= \u0026#39;Exchange Online (Plan 1)\u0026#39; \u0026#39;MCOSTANDARD_MIDMARKET\u0026#39;\t= \u0026#39;Lync Online (Plan 1)\u0026#39; \u0026#39;SHAREPOINTENTERPRISE_MIDMARKET\u0026#39;\t= \u0026#39;SharePoint Online (Plan 1)\u0026#39; \u0026#39;OFFICESUBSCRIPTION\u0026#39;\t= \u0026#39;Office ProPlus\u0026#39; \u0026#39;YAMMER_MIDSIZE\u0026#39;\t= \u0026#39;Yammer\u0026#39; \u0026#39;DYN365_ENTERPRISE_PLAN1\u0026#39;\t= \u0026#39;Dynamics 365 Customer Engagement Plan Enterprise Edition\u0026#39; \u0026#39;ENTERPRISEPREMIUM_NOPSTNCONF\u0026#39;\t= \u0026#39;Enterprise E5 (without Audio Conferencing)\u0026#39; \u0026#39;ENTERPRISEPREMIUM\u0026#39;\t= \u0026#39;Enterprise E5 (with Audio Conferencing)\u0026#39; \u0026#39;MCOSTANDARD\u0026#39;\t= \u0026#39;Skype for Business Online Standalone Plan 2\u0026#39; \u0026#39;PROJECT_MADEIRA_PREVIEW_IW_SKU\u0026#39;\t= \u0026#39;Dynamics 365 for Financials for IWs\u0026#39; \u0026#39;STANDARDWOFFPACK_IW_STUDENT\u0026#39;\t= \u0026#39;Office 365 Education for Students\u0026#39; \u0026#39;STANDARDWOFFPACK_IW_FACULTY\u0026#39;\t= \u0026#39;Office 365 Education for Faculty\u0026#39; \u0026#39;EOP_ENTERPRISE_FACULTY\u0026#39;\t= \u0026#39;Exchange Online Protection for Faculty\u0026#39; \u0026#39;EXCHANGESTANDARD_STUDENT\u0026#39;\t= \u0026#39;Exchange Online (Plan 1) for Students\u0026#39; \u0026#39;OFFICESUBSCRIPTION_STUDENT\u0026#39;\t= \u0026#39;Office ProPlus Student Benefit\u0026#39; \u0026#39;STANDARDWOFFPACK_FACULTY\u0026#39;\t= \u0026#39;Office 365 Education E1 for Faculty\u0026#39; \u0026#39;STANDARDWOFFPACK_STUDENT\u0026#39;\t= \u0026#39;Microsoft Office 365 (Plan A2) for Students\u0026#39; \u0026#39;DYN365_FINANCIALS_BUSINESS_SKU\u0026#39;\t= \u0026#39;Dynamics 365 for Financials Business Edition\u0026#39; \u0026#39;DYN365_FINANCIALS_TEAM_MEMBERS_SKU\u0026#39; = \u0026#39;Dynamics 365 for Team Members Business Edition\u0026#39; \u0026#39;FLOW_FREE\u0026#39;\t= \u0026#39;Microsoft Flow Free\u0026#39; \u0026#39;POWER_BI_PRO\u0026#39;\t= \u0026#39;Power BI Pro\u0026#39; \u0026#39;O365_BUSINESS\u0026#39;\t= \u0026#39;Office 365 Business\u0026#39; \u0026#39;DYN365_ENTERPRISE_SALES\u0026#39;\t= \u0026#39;Dynamics Office 365 Enterprise Sales\u0026#39; \u0026#39;RIGHTSMANAGEMENT\u0026#39;\t= \u0026#39;Rights Management\u0026#39; \u0026#39;PROJECTPROFESSIONAL\u0026#39;\t= \u0026#39;Project Professional\u0026#39; \u0026#39;VISIOONLINE_PLAN1\u0026#39;\t= \u0026#39;Visio Online Plan 1\u0026#39; \u0026#39;EXCHANGEENTERPRISE\u0026#39;\t= \u0026#39;Exchange Online Plan 2\u0026#39; \u0026#39;DYN365_ENTERPRISE_P1_IW\u0026#39;\t= \u0026#39;Dynamics 365 P1 Trial for Information Workers\u0026#39; \u0026#39;DYN365_ENTERPRISE_TEAM_MEMBERS\u0026#39;\t= \u0026#39;Dynamics 365 For Team Members Enterprise Edition\u0026#39; \u0026#39;CRMSTANDARD\u0026#39;\t= \u0026#39;Microsoft Dynamics CRM Online Professional\u0026#39; \u0026#39;EXCHANGEARCHIVE_ADDON\u0026#39;\t= \u0026#39;Exchange Online Archiving For Exchange Online\u0026#39; \u0026#39;EXCHANGEDESKLESS\u0026#39;\t= \u0026#39;Exchange Online Kiosk\u0026#39; \u0026#39;SPZA_IW\u0026#39;\t= \u0026#39;App Connect\u0026#39; \u0026#39;WINDOWS_STORE\u0026#39;\t= \u0026#39;Windows Store for Business\u0026#39; \u0026#39;MCOEV\u0026#39;\t= \u0026#39;Microsoft Phone System\u0026#39; \u0026#39;VIDEO_INTEROP\u0026#39;\t= \u0026#39;Polycom Skype Meeting Video Interop for Skype for Business\u0026#39; \u0026#39;SPE_E5\u0026#39;\t= \u0026#39;Microsoft 365 E5\u0026#39; \u0026#39;SPE_E3\u0026#39;\t= \u0026#39;Microsoft 365 E3\u0026#39; \u0026#39;ATA\u0026#39;\t= \u0026#39;Advanced Threat Analytics\u0026#39; \u0026#39;MCOPSTN2\u0026#39;\t= \u0026#39;Domestic and International Calling Plan\u0026#39; \u0026#39;FLOW_P1\u0026#39;\t= \u0026#39;Microsoft Flow Plan 1\u0026#39; \u0026#39;FLOW_P2\u0026#39;\t= \u0026#39;Microsoft Flow Plan 2\u0026#39; \u0026#39;DeveloperPack\u0026#39;\t= \u0026#39;OFFICE 365 ENTERPRISE E3 DEVELOPER\u0026#39; \u0026#39;EMSPremium\u0026#39;\t= \u0026#39;ENTERPRISE MOBILITY + SECURITY E5\u0026#39; \u0026#39;RightsManagemnt\u0026#39;\t= \u0026#39;AZURE INFORMATION PROTECTION PLAN 1\u0026#39; \u0026#39;DYN365_ENTERPRISE_CUSTOMER_SERVICE\u0026#39; = \u0026#39;DYNAMICS 365 FOR CUSTOMER SERVICE ENTERPRISE EDITION\u0026#39; \u0026#39;POWERFLOW_P1\u0026#39;\t= \u0026#39;Microsoft PowerApps Plan 1\u0026#39; \u0026#39;POWERFLOW_P2\u0026#39;\t= \u0026#39;Microsoft PowerApps Plan 2\u0026#39; \u0026#39;AAD_PREMIUM_P1\u0026#39;\t= \u0026#39;Azure Active Directory Premium P1\u0026#39; \u0026#39;AAD_PREMIUM_P2\u0026#39;\t= \u0026#39;Azure Active Directory Premium P2\u0026#39; \u0026#39;TEAMS_EXPLORATORY\u0026#39;\t= \u0026#39;Teams Exploratory\u0026#39; \u0026#39;MDATP_XPLAT\u0026#39;\t= \u0026#39;Microsoft Defender for Endpoint P2\u0026#39; } Above we see a simple hash table mapping all skus to the friendly name. Simply index the hashtable to get the value $FriendlyLicenses['AAD_Basic'] for example.\nNext, we connect to Graph with the appropriate permission scopes\n# Get necessary permission scoped $perms = \u0026#39;User.Read.All\u0026#39;, \u0026#39;User.ReadWrite.All\u0026#39;,\u0026#39;Directory.Read.All\u0026#39; Connect-MgGraph -UseDeviceAuthentication -ForceRefresh -Scopes $perms Select-MgProfile beta Next, we can initialize some neccesary varibles. We need to get the license skus currenly purchased under the tenant, including the total cound and count used. Then we need to get a list of all users.\n[Array]$Skus = Get-MgSubscribedSku # Get all skus in the tenant $TenantLicenseDetails = $Skus | select SkuPartNumber, ConsumedUnits, @{ n = \u0026#39;TotalUnits\u0026#39;; e = { $_.prepaidunits.enabled } }, @{ n = \u0026#39;FriendlyName\u0026#39;; e= {$_ | foreach { $FriendlyLicenses[$_.SkuPartNumber] } } } # Get the Sku name, the total number assigned, the number used, and the friendly name [Array]$Users = Get-MGUser -All # Get all user accounts $i = 0 # Increment variable Now we need to loop through the users and build a record of each users license assignment(s)\nforeach ($user in $Users) { Write-Progress -Activity \u0026#34;Processing User License details\u0026#34; -Status \u0026#34;Working on $($user.displayname)\u0026#34; -PercentComplete (($i / $Users.Count) * 100) $user.LicenseDetails = Get-MgUserLicenseDetail -UserId $user.id Start-Sleep -Milliseconds 400 $i++ } Finally, lets filter out users without any license, and build the properties for our report\n$UserLicenseDetails = $Users | where LicenseDetails | select UserPrincipalName, @{ n = \u0026#39;Licenses\u0026#39; e = { ($_ | foreach { $_.licensedetails | foreach { if ($FriendlyLicenses[$_.SkuPartNumber]) { $FriendlyLicenses[$_.SkuPartNumber] } else { $_.SkuPartID } } }) -join \u0026#39;;\u0026#39; } } Now we can export the report. I added in a function to open a handy save file dialog box to prompt for a location and name for the report file.\n#File Save box function Function Get-SaveFileLocation { [System.Reflection.Assembly]::LoadWithPartialName(\u0026#34;System.windows.forms\u0026#34;) | Out-Null $SaveFileDialog = New-Object System.Windows.Forms.SaveFileDialog $SaveFileDialog.initialDirectory = [system.Environment]::GetFolderPath(\u0026#39;Desktop\u0026#39;) $SaveFileDialog.filter = \u0026#34;All files (*.*)| *.*\u0026#34; $SaveFileDialog.ShowDialog() | Out-Null $SaveFileDialog.filename } Write-Verbose \u0026#34;Enter Save FilePath\u0026#34; $savepath = Get-SaveFileLocation # Open Save File dialogbox $UserLicenseDetails | Export-Csv $savepath -NoTypeInformation # Export to CSV \u0026amp; $savepath # Automatically open the CSV once complete See the full script in my Github Repository\rIf you have any questions or comments, feel free to drop them down below, or shoot me an email.\n", 
            "url": "\/post\/o365-license-report-microsoft-graph\/"
        },
        
        
        
        "\/post\/backup-and-reset-windows-user-profile\/": {
            
            "title": "Backup and Reset Windows User Profile",
            "tags": ["Windows","PowerShell",],
            "content": "Premise If you use Windows long enough, eventually you will run into a broken user profile. Sometimes its the start menu that busted, or the Windows store wont open etc. If the typical recommendations of sfc / dism / re-register appx packages with PowerShell fails to remedy the issue, see if the issue is isolated to the user profile. Log into another Windows user account and see if the issue persists. If the issue is not present in another Windows account, then you have a case of a borked Windows user profile.\nYou can try to keep fixing the issue, but Ive found its typically faster and easier to just backup and \u0026ldquo;blow-out\u0026rdquo; the user profile\nBacking up user data and removing the profile. Create a backup folder to store files. C:\\backup for example.\nExport browser data, including saved passwords, bookmarks etc. If you store passwords in Chrome/Firefox/Edge and you are not syncing an account, the passwords will be lost unless they are exported.\nMake note of any obvious user customizations, such as taskbar layout, outlook layout, background pictures etc.\nMake note of any user installed software. This can be done by checking the Uninstall registry key under HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\nSign out and sign into a local admin account\nRemove the affected user profile registry key under HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\\ The keyname will be the SID of the user account.\nReboot\nAfter reboot, log back into the local admin account. Rename the user folder adding .bak to the name.\nSome of this process can be easily automated. The following script will export a list of user specific programs, also backup and remove the user profile registry key.\n#Requires -RunAsAdministrator $userprofiles = (Get-ChildItem registry::\u0026#34;HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\\\u0026#34; | get-itemproperty).pschildname $users = foreach ($user in ($userprofiles | where { $_.Length -gt 20 })) { $sid = $user try { [pscustomobject]@{ \u0026#39;UserName\u0026#39; = ([System.Security.Principal.SecurityIdentifier]($sid)).translate([System.Security.Principal.NTAccount]).value \u0026#39;SID\u0026#39;\t= $sid \u0026#39;ProfilePath\u0026#39; = (Get-ItemProperty registry::HKEY_LOCAL_MACHINE\\\u0026#34;SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\\$sid\u0026#34;).ProfileImagePath } } Catch {} } function Welcome { Write-Host \u0026#34;####################################################################################################\u0026#34; Write-Host \u0026#34;User Profile Backup/Removal Tool Version 1.0`nAuthor: David Just\u0026#34; -ForegroundColor DarkCyan -BackgroundColor Black Write-Host \u0026#34;Welcome to the User Profile Backup/Removal Tool\u0026#34; -ForegroundColor Green -BackgroundColor Black Write-Host \u0026#34;#################################################################################################### `r`n\u0026#34; Write-Warning \u0026#34;This tool performs potentially descructive actions. `nBefore running, please export and save browser passwords, bookmarks etc.\u0026#34; pause Write-Host \u0026#34;[1] Backup/remove user profile registry key and reboot`n[2] Rename user profile folder\u0026#34; $global:option = [int](Read-Host \u0026#34;Which step would you like to perform?\u0026#34;) } function ListUserProgram { param ( $SID, $ProfilePath ) reg load HKU\\brokenuser $ProfilePath\\NTUSER.DAT $RegPath = \u0026#34;registry::HKU\\brokenuser\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\u0026#34; try { $softwareTable = Get-Childitem $RegPath -ErrorAction Stop | Get-ItemProperty | where displayname | select displayname, displayversion New-Item -ItemType directory -Path $env:SystemDrive\\backup -force | Out-Null $softwareTable | Export-Csv \u0026#34;$env:SystemDrive\\backup\\usersoftware.csv\u0026#34; -NoTypeInformation } Catch { $_ \u0026#34;Error exporting user software list\u0026#34; \u0026#34;Stopping Operation\u0026#34; reg unload HKU\\brokenuser sleep 5 exit 1 } } Welcome function RemoveAndBackupUserProfile { [Cmdletbinding(SupportsShouldProcess)] param ( [string]$SID, [string]$profilepath ) reg export \u0026#34;HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\\$sid\u0026#34; $env:SystemDrive\\backup\\profile.reg $profilepath | Out-File $env:SystemDrive\\backup\\profilepath.txt Remove-Item registry::\u0026#34;HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\\$sid\u0026#34; -Recurse CheckandSuspendBitlocker\t\u0026#34;Profile removed from registry. Rebooting in 5 seconds\u0026#34; shutdown /r /t 5 } function CheckandSuspendBitlocker # Suspend Bitlocker protection for reboot { $Status = (Get-BitLockerVolume -MountPoint $env:systemdrive).protectionstatus if ($Status -eq \u0026#34;On\u0026#34;) { \u0026#34;Suspending bitlocker protection...\u0026#34; Suspend-BitLocker -MountPoint $env:SystemDrive -RebootCount 1 } } switch ($option) { 1 { $index = 1 foreach ($user in $users) { \u0026#34;[$index] {0}\u0026#34; -f $user.username $index++ } $Selection = [int](Read-Host \u0026#34;Which user account do you wish to backup and remove?\u0026#34;) - 1\tWrite-Host \u0026#34;Exporting User Program List...\u0026#34; sleep 1 ListUserProgram -SID ($users[$Selection]).SID -ProfilePath ($users[$Selection]).ProfilePath \u0026#34;Program list saved to $env:SystemDrive\\backup\\usersoftware.csv\u0026#34; Pause RemoveAndBackupUserProfile -SID ($users[$Selection]).SID -profilepath ($users[$Selection]).ProfilePath -Confirm } 2 { $profilepath = Get-Content $env:SystemDrive\\backup\\profilepath.txt Rename-Item $profilepath -NewName ($profilepath + \u0026#34;.bak\u0026#34;) \u0026#34;Renamed {0} to {1}\u0026#34; -f $profilepath,($profilepath + \u0026#34;.bak\u0026#34;) sleep 5 } } Logout. Log back in as the original user All user data still remains in the original renamed user folder (including registry information). If needed, move any data needed back from the backup folder. Reinstall any user specific programs. If you run the script, these will be listed out in the CSV file under C:\\backup. And thats it! Sometimes its just better to cut your losses and start fresh.\n", 
            "url": "\/post\/backup-and-reset-windows-user-profile\/"
        },
        
        
        
        "\/post\/power-automate-send-data-from-powershell-to-excel\/": {
            
            "title": "Get Data from workstations and send to an Excel Table for free",
            "tags": ["O365","Intune","Power Automate","Microsoft Graph",],
            "content": "Premise There are times when I encounter a situation where I want to gather some data from workstations and store it in a spreadsheet / table ect. for tracking purposes. Recently I was working with a client to deploy a cloud printing solution. The on prem print environment was somewhat complex with multiple shared printers some of which were locked down to AD security groups. I needed a way to get a pre-deployment printer inventory for each workstation, then compare a post deployment inventory. In came PowerAutomate and PowerShell.\nIn a previous article, I covered how to use Power Automate to shuttle data from a workstation/server into an Azure Table using Power Automate and the HTTP request trigger. This method is straight forward, easy, and works great but has a catch. The HTTP trigger is a premium feature which requires a $15/MONTH license. How can we accomplish the same result more or less completely for free? This article will explain the method I came up with using PowerShell, the Microsoft Graph and Power Automate.\nGetting a list of printers Getting a list of printers from each workstation is fairly straight forward using PowerShell.\nUse the Get-Printer cmdlet on each workstation to get a list of printers. Filter for only shared printers. Run the script as the logged on user, so we get the user connections. Move the results off the workstation to a central repository. Lets put it together. First getting the list of printers :\n# Get list of installed shared printers $printers = Get-Printer | where type -eq \u0026#34;Connection\u0026#34; $printerList = foreach ($printer in $printers){ [pscustomobject]@{ \u0026#39;ComputerName\u0026#39; = hostname \u0026#39;PrinterName\u0026#39; = $printer.name \u0026#39;PrinterPortname\u0026#39; = $printer.portname \u0026#39;Type\u0026#39; = $printer.type } $printerJSON = $printerList | ConvertTo-JSON Setting up the framework to send email using Graph Alright now how can we get this data into table and trigger a PowerAutomate flow for free? Send Mail with Microsoft graph. Practical 365 has a great article on how to send email with Microsoft Graph using PowerShell\rThis consits of 3 steps\nCreate an App registration in AzureAD Give the app registration mail.send application rights. Create an application secret to use for Authentication. Head over to the Azure AD Portal\rClick on Azure Active Directory, then App Registrations Click new registration. Give the app a descriptive name Under \u0026lsquo;API Permissions\u0026rsquo; click app permission. Under Microsoft Graph, Select the application permission \u0026lsquo;Mail.Send\u0026rsquo; Grant Admin Consent. Create an app secret Go to \u0026lsquo;Certificate and Secrets\u0026rsquo; Click \u0026lsquo;New Client Secret\u0026rsquo; (Optional) Enter a description. Copy down the secret value for later Go to overview, copy down the tenant ID and app ID for later. Once we have the app created, we need to prepare exchange:\nCreate a shared mailbox for our sending mail account Create an application policy to restrict our app from sending as any mailbox other than our service account Create a mail enabled security group to apply the application policy to We can easily do this in PowerShell:\n$mailsender = [mailaddress]\u0026#39;flowservice@justgeeks.co\u0026#39; $appID = \u0026#39;APP ID you copied down before\u0026#39; New-Mailbox -Shared -Name $mailsender.user -DisplayName $mailsender.user -Alias $mailsender.user -PrimarySmtpAddress $mailsender.address New-DistributionGroup -Type Security -Name \u0026#39;GraphSendAllowed\u0026#39; -Members $mailsender.user # create security group to add graph mail sender to Set-DistributionGroup \u0026#39;GraphSendAllowd\u0026#39; -HiddenFromAddressListsEnabled $true # hide from distribution list New-ApplicationAccessPolicy -AccessRight RestrictAccess -AppId $AppID -PolicyScopeGroupId \u0026#39;GraphSendAllowed\u0026#39; -Description \u0026#34;Restrict this app\u0026#39;s access to flow service account\u0026#34; # apply restriction policy to only allow app send as members of GraphSendAllowed Send data from each workstation via email Now that we have a way to send email with the Microsoft Graph, we can craft a PowerShell script to run per workstation to send the data we want via email. We will take the PowerShell snippet from before to get the list of printers. Then add the steps to send an email with graph and attach the list of printers as an attachment in the email. This way we can parse the attachment later for the data we want to store.\n# List of printers $printers = Get-Printer | where type -eq \u0026#34;Connection\u0026#34; $printerList = foreach ($printer in $printers){ [pscustomobject]@{ \u0026#39;ComputerName\u0026#39; = $env:COMPUTERNAME \u0026#39;PrinterName\u0026#39; = $printer.name \u0026#39;PrinterPortname\u0026#39; = $printer.portname \u0026#39;Type\u0026#39; = $printer.type } } # Convert list to JSON to later parse in PowerAutomate $json = $printerList | ConvertTo-JSON #Azure App Registration Variables $clientID = \u0026#34;125d565f-df97-437a-a5fa-1e119a359a8d\u0026#34; $Clientsecret = \u0026#34;4e5b5d~lkjjio98LyOOE94i_56daskjllk\u0026#34; $tenantID = \u0026#34;c7d54f65-0023-4525-a44e-eed2653923ae\u0026#34; # Mail details $from = \u0026#34;flowservice@davidjust.com\u0026#34; $to = \u0026#34;david@davidjust.com\u0026#34; $subject = \u0026#34;PrinterResults\u0026#34; #Get an auth token for the GRAPH API using the app registration $tokenBody = @{ Grant_Type = \u0026#34;client_credentials\u0026#34; Scope = \u0026#34;https://graph.microsoft.com/.default\u0026#34; Client_Id = $clientId Client_Secret = $clientSecret } $tokenResponse = Invoke-RestMethod -Uri \u0026#34;https://login.microsoftonline.com/$tenantID/oauth2/v2.0/token\u0026#34; -Method POST -Body $tokenBody $headers = @{ \u0026#34;Authorization\u0026#34; = \u0026#34;Bearer $($tokenResponse.access_token)\u0026#34; \u0026#34;Content-type\u0026#34; = \u0026#34;application/json\u0026#34; } $URL = \u0026#34;https://graph.microsoft.com/v1.0/users/$from/sendMail\u0026#34; $bytes = [System.Text.Encoding]::UTF8.GetBytes($json) $base64 = [System.Convert]::ToBase64String($bytes) # Craft the JSON POST Body $body = @\u0026#34; { \u0026#34;message\u0026#34;: { \u0026#34;subject\u0026#34;: \u0026#34;$subject\u0026#34;, \u0026#34;body\u0026#34;: { \u0026#34;contentType\u0026#34;: \u0026#34;Text\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Results\u0026#34; }, \u0026#34;toRecipients\u0026#34;: [ { \u0026#34;emailAddress\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;$to\u0026#34; } } ], \u0026#34;attachments\u0026#34;: [ { \u0026#34;@odata.type\u0026#34;: \u0026#34;#microsoft.graph.fileAttachment\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;json.txt\u0026#34;, \u0026#34;contentType\u0026#34;: \u0026#34;text/plain\u0026#34;, \u0026#34;contentBytes\u0026#34;: \u0026#34;$base64\u0026#34; } ] } } \u0026#34;@ # Finally, send the email using Graph Invoke-RestMethod -Method POST -Uri $URL -Headers $headers -Body $Body Power Automate Flow Now we have framework from which to send emails through the Microsoft Graph. Now lets move on to creating our Power Automate Flow.\nBefore adding creating our PowerAutomate flow, we need to prepare an excel workbook to store results Go to portal.office.com and create a blank excel workbook. Click insert, table, check my table has headers. Click OK Add additional columns and edit each column with the property names you wish to store in the table Click File, SaveAs, then rename the workbook and change the location if you wish. Login to https://flow.microsoft.com\r. Created an automated flow with the trigger \u0026ldquo;O365 When a new email arrives v3\u0026rdquo;. Enter a name and click create. Expand advanced. Enter the flow service email address in the from field and enter the subject of incoming emails to capture. Select only with attachments. Click new step. Search for \u0026ldquo;Get Attachment (V2)\u0026rdquo;\nUnder Message ID, select the dynamic content \u0026ldquo;Message ID\u0026rdquo; from our previous step For attachment ID, select \u0026ldquo;Attachments Attachment ID\u0026rdquo;. This will automatically create an apply to each step. Click add an action for the next step Search for \u0026ldquo;Compose\u0026rdquo;. Here we need to enter an expression for inputs. Select expression, then type decodeBase64(). Click inside the parantheses and under dynamic content, select the dynamic \u0026ldquo;Content Bytes\u0026rdquo; to add the content of the attachment. The full expression should look like this decodeBase64(outputs('Get_Attachment_(V2)')?['body/contentBytes']) Click add action.\nSearch for \u0026ldquo;Parse JSON\u0026rdquo; In content, select the dynamic content \u0026ldquo;Outputs\u0026rdquo; from the compose action. For schema, we can simply generate from sample. Open PowerShell, and paste the code for the data we want to generate. Pipe to ConvertTo-JSON to generate a JSON object. Paste the output into the sample field $printers = foreach ($printer in (get-printer)){ [pscustomobject]@{ \u0026#39;ComputerName\u0026#39; = $env:COMPUTERNAME \u0026#39;PrinterName\u0026#39; = $printer.name \u0026#39;PrinterPortname\u0026#39; = $printer.portname \u0026#39;Type\u0026#39; = $printer.type } } $printers | ConvertTO-JSON Next add one more action in under apply to each. Search for the action \u0026ldquo;Add a row into a table (Excel Online)\u0026rdquo;\nFill in the fields for location picking the excel workbook you prepared earlier. For the table fields, select the dynamic content from the parse JSON action. For the final step, add a new step. Search for \u0026ldquo;Delete an email (v2)\u0026rdquo;. Add the dynamic content No save the flow. Go ahead and test the entire PowerShell script. You should see a sucessful run. You can even see the excel table being filled in real time!\nFinal thoughts While this isnt the most straight forward or simpllist solution, you cant beat free. I do not like the idea of storing secrets inside scripts, but you can mitigate any risk of misuse by creating the application policy as shown in exchange. Also, when you are done with your script deployment, simply delete the secret inside the app registration. Create a new secret each time you wish to run this flow. If you have any suggestions for improving this flow or another way of doing similar, please let me know!\n", 
            "url": "\/post\/power-automate-send-data-from-powershell-to-excel\/"
        },
        
        
        
        "\/tags\/power-automate\/": {
            
            "title": "Power Automate",
            "tags": [],
            "content": "", 
            "url": "\/tags\/power-automate\/"
        },
        
        
        
        "\/tags\/rest-api\/": {
            
            "title": "REST API",
            "tags": [],
            "content": "", 
            "url": "\/tags\/rest-api\/"
        },
        
        
        
        "\/post\/working-with-microsoft-graph-powershell-sdk\/": {
            
            "title": "Working with the Microsoft Graph PowerShell SDK",
            "tags": ["O365","Microsoft Graph","PowerShell","REST API",],
            "content": "What is an API anyway? API stands for \u0026ldquo;Application Interface\u0026rdquo;. In simplest terms, APIs are services that bridge and allow two systems to interact. When we are talking about web services, such as those in M365, API usually refer to a REST API. I like this explanation from AWS:\rAPI architecture is usually explained in terms of client and server. The application sending the request is called the client, and the application sending the response is called the server. So in the weather example, the bureau’s weather database is the server, and the mobile app is the client.\nREST APIs are the most popular and flexible APIs found on the web today. The client sends requests to the server as data. The server uses this client input to execute internal functions and returns output data back to the client. Let’s look at REST APIs in more detail below.\nREST supports the following operations, known as \u0026ldquo;Methods\u0026rdquo;\nGET - Just like it sounds, gets data from a resource POST - Post data, or create data PATCH - update a specific portion of data on a resource PUT - Like PATCH, updates but updates the entire resource (think replacment) DELETE - Self explanatory. Deletes data/resource You may not be away, but all of the core services of Microsoft 365, Exchange Online, Azure AD, SharePoint, Intune, Defender for Endpoint etc., expose data through APIs. When you go into the O365 admin center and view a user account, the web browser is interacting with an API to pull that data and expose it to you. When you make a change to a user, group, setting, you are sending a request through an API to make that change.\nWhat is the big deal about the Microsoft Graph? When Office 365 was first introduced, every service had its own specific API. Microsoft introduced the Graph API in an effort to consolodate resources. With Graph, data can be accessed from most services in O365 including Exchange, AzureAD, SharePoint/OneDrive, Security and Compliance etc.\nAccording to Microsoft:\nMicrosoft Graph represents our best-in-breed API surface. It offers a single unified endpoint to access Azure AD services and Microsoft 365 services such as Microsoft Teams and Microsoft Intune. Microsoft Graph API\u0026rsquo;s usage has more than doubled that of Azure AD Graph, and in the past two years we have added 167 new features. All new functionalities will only be available through the Microsoft Graph.\nMicrosoft has made clear their intentions to get rid of the Azure AD API\r. That means the associated PowerShell modules (AzureAD / MSOL) will stop working. The replacement for these is the Microsoft Graph PowerShell SDK.\nGetting familiar with the Microsoft Graph A good place to start is the Microsoft Graph Reference\rwhich lists in detail every endpoint in the API.\nBefore we connect to Graph, we first need to know what permissions we are going to need as we need to specify the permission scopes during the connection.\nFor example, if we look at listing users\rwe see the following permission scopes listed :\nPermission type Permissions (from least to most privileged) Delegated User.ReadBasic.All, User.Read.All, User.ReadWrite.All Directory.Read.All, Directory.ReadWrite.All Application User.Read.All, User.ReadWrite.All, Directory.Read.All, Directory.ReadWrite.All Delegated permissions are what we will use and are the permissions needed when authenticating with a user account. Application permissions are permissions assigned to an application in AzureAD.\n⚠ Note: Its important to note, there are two versions of the Microsoft Graph API, v1.0 and beta. V1.0 is considered the stable branch, beta is where new features are being continually added. Microsoft cautions the beta endpoints are subject to change, so stick with v1.0 unless you need a feature only available in the beta version. We will use the List Users endpoint in the following example.\nGetting started the Microsoft Grah PowerShell SDK Installation To get started, we first need to install the SDK. Installation is simple using Install-Module.\nInstall-Module Microsoft.Graph -forcerefresh ⚠ Note: The PowerShell SDK will work with *Windows PowerShell* (i.e. the PowerShell shipped with Windows / v5.1) and with the latest cross platform *PowerShell* version 7.2 at the time of this. Microsoft recommends using PowerShell 7+ to work with the SDK. Lets connect to Graph with *User.Read.All* so we can read all accounts in AzureAD. Connecting to Graph Connect-MGGRaph -scopes \u0026#39;User.Read.All\u0026#39; 🛈 Tip: To specify multiple scopes, simply comma separate each scope.\rOnce connected, run Get-MGUser to get a list of all users in the directory :\nOk great, so we listed out some users. But how the heck do you know what commands to run? Well good question. Unfortunately, the documentation for the PowerShell SDK is not very good. Most cmdlets have little to no actual useful documentation as to what they do. I believe this is because Microsoft is using an automated process to generate cmdlets that map directly to the REST API calls.\nTo find out what cmdlet maps to a particular endpoint, use Find-MGGraphCommand and specify the direct HTTP endpoint. For example:\nFinding cmdlets Find-MgGraphCommand -URI \u0026#39;/users\u0026#39; Gives the following output :\nWe can see Get-MGUser and New-MGUser, the REST method the associated permission scopes needed.\nIf you would like to use cmdlets with the beta version of Graph, you can switch to beta using :\nSelect-MgProfile -Name \u0026#34;beta\u0026#34; In the event you cannot find a corresponding cmdlet in the SDK, or the cmdlet doesnt work as expected (it\u0026rsquo;s happened to me more than once), you can use the catch-all generic cmdlet Invoke-MGGraphRequest\n$Users = Invoke-MGGraphRequest -method GET -uri \u0026#34;v1.0\\users\u0026#34; $User.Value When using Invoke-MGGraphRequest, we get the raw data from Graph and need to expand the \u0026ldquo;value\u0026rdquo; property. We also need to specify which version of Graph we wish to query, v1.0 or beta.\nLets look at an example of sending a PATCH request to Graph to set the password policy on a user account :\n# Specify the User Principal Name for the user $UPN = \u0026#39;AdeleV@x745w.onmicrosoft.com\u0026#39; # Get the user GUID $userID = (Get-MGUser -userid $UPN).id # Create the body paramater for the PATCH request with a hash table $body = @{\u0026#34;PasswordPolicies\u0026#34; = \u0026#34;DisablePasswordExpiration\u0026#34;} # Send the PATCH request to update the password policy Invoke-MGGraphRequest -method PATCH -uri \u0026#34;v1.0\\users\\$userid\u0026#34; -body $body #Confirm the password policy updated Invoke-MGGraphRequest -method GET -uri \u0026#34;v1.0\\users\\$userid`?`$select=PasswordPolicies\u0026#34; With the above PATCH request example, we are updating just the password policy on the user account for AdeleV@x745w.onmicrosoft.com\rWhen you are finished, don\u0026rsquo;t forget to disconnect with Disconnect-MGGraph\nHopefully this is enough to get you started using the Microsoft Graph PowerShell SDK. Stayed tuned, I will provide some sample scripts to help furhter your journey down the graph.\n", 
            "url": "\/post\/working-with-microsoft-graph-powershell-sdk\/"
        },
        
        
        
        "\/macosresources\/": {
            
            "title": "Helpful macOS Resources",
            "tags": ["O365","Intune","macOS",],
            "content": " Office Apps : https://macadmins.software/\rUseful tools : https://www.macadmin.info/#managementtools\rProfile Creator : https://github.com/ProfileCreator/ProfileCreator\rBest Practices : https://techcommunity.microsoft.com/t5/intune-customer-success/best-practice-examples-for-configuring-macos-apps-with-microsoft/ba-p/2564255\rDeploying Office : https://docs.microsoft.com/en-us/deployoffice/mac/preferences-outlook#disable-skype-for-business-online-meetings\rOneDrive config : https://docs.microsoft.com/en-us/onedrive/deploy-and-configure-on-macos#filesondemandenabled\rCustom onboarding splash screen : https://techcommunity.microsoft.com/t5/intune-customer-success/build-a-macos-onboarding-splash-screen-with-microsoft-endpoint/ba-p/2770980\r", 
            "url": "\/macosresources\/"
        },
        
        
        
        "\/post\/intune-for-macos-configure-profiles\/": {
            
            "title": "Intune for macOS Part 2 - Setup BYOD enrollment and Configure macOS Profiles",
            "tags": ["O365","Intune","macOS",],
            "content": "Setup BYOD Enrollment In part 1\r, we explored how to setup a macOS virtual machine for testing. Now lets look at actually configuring Intune. The first thing we need to do is get an Apple MDM push certificate.\nNavigate to endpoint.microsoft.com \u0026lt; Devices \u0026lt; Enroll Devices \u0026lt; Apple Enrollment. Download the CSR. Follow the link “Create your MDM Push Certificate” Sign into your Apple ID (or create one if you do not have one) Click create certificate. Accept the terms of service. Upload the CSR you downloaded from Intune. Download the newly created MDM push certificate and upload to Intune. At this point BYOD enrollment using the company portal app will work, but we need to setup some policies.\nSee the official Microsoft doc for the BYOD enrollment flow\rConfiguration Profiles The official policies supported out of the box in Intune are a bit limited currently.\nCurrently available configuration policies in Intune: Device Features Device Restrictions Endpoint Protection Extensions VPN Wi-Fi Wired networks For a full listing of including settings, see the official documentation macOS device settings in Microsoft Intune | Microsoft Docs\nCreate Custom Configuration Profiles For settings not available in the included policies, we can upload custom config profiles to Intune. To do this officially, you would need Apple server with Apple Profile Manager. I do not have the luxury of having access to apple server, so instead I recommend using Profile Creator over on GitHub. Simply download the latest release version and run on your test VM with macOS.\nWhen you open Profile Creator for the first time, you will get a warning about the app being from an unidentified developer Open System preferences, under general, select “Open Anyway” Once you have profile creator open, click the + icon to start a new payload.\nOn the general page, enter a name for the profile, a payload description and organization name. For this example, we will create a profile for software update settings.\nNow, click the settings gear at the top right and under platform, uncheck iOS and tvOS.\nThe lefthand pane displays a list of all avaliable profiles. Select the profile you wish to create, in this case \u0026ldquo;Software Update\u0026rdquo;\nClick + next to the settings you would like to add to the profile. Once you are done, click the add button at the top right.\nSave and export the file. The default save location is the documents folder.\nUpload custom profile to Intune Now that we have the profile settings saved to an xml file, we can upload it to Intune.\nGo to Device \u0026lt; Configuration Profiles \u0026lt; Create Profile \u0026lt; macOS \u0026lt; Templates \u0026lt; Custom\nCreate a profile name, select the appropriate deployment channel, upload the exported profile, then assign to the appropriate user group.\nYou can find the custom profiles I have created here https://github.com/djust270/macOS-Intune-Profiles\rIn the next part, I will cover software deployment using shell scripts.\nHelpful macOS Resources\r", 
            "url": "\/post\/intune-for-macos-configure-profiles\/"
        },
        
        
        
        "\/tags\/macos\/": {
            
            "title": "macOS",
            "tags": [],
            "content": "", 
            "url": "\/tags\/macos\/"
        },
        
        
        
        "\/about\/": {
            
            "title": "About the author",
            "tags": [],
            "content": "\rHi there My name is David Just. I am a technology enthusiast, nerd, father, and husband. Welcome to my personal blog.\nI have a passion for learning and sharing the things I have learned. As a Systems Administrator, I have found a passion for automation and coding, particularly with PowerShell. This blog is a place for me to jot down my thoughts and share interesting things along this journey of life.\nThank you for visiting.\n", 
            "url": "\/about\/"
        },
        
        
        
        "\/post\/intune-install-software-with-winget\/": {
            
            "title": "Intune Deploy Software with WinGet",
            "tags": ["O365","Intune","WinGet",],
            "content": "Ever since the WinGet package manager was announced, I wanted to find ways to leverage the package manager to simplify deploying software to endpoints. After doing some research and testing, I found that WinGet was unfortunately not designed to be run in SYSTEM context. It was designed to be run under a user account. There is an open issue on GitHub currently and many admins, myself included, would really like WinGet to be designed with enterprise use in mind. There was a crafty user on Github however that found that WinGet.exe is a proxy application for \u0026ldquo;AppInstallerCLI.exe\u0026rdquo; which can be ran as system. The executable is found under C:\\Program Files\\WindowsApps\\Microsoft.DesktopAppInstaller_1.17.10271.0_x64__8wekyb3d8bbwe\nEDIT: As of writing this, it seems for the latest version of WinGet, WinGet.exe is now located in the DesktopAppInstaller folder, AppInstallerCLI.exe is no longer here. You can call WinGet.exe directly. In my script, I check for both WinGet.exe and AppInstallerCLI.exe\nRunning this executable directly works just fine under SYSTEM. I created a simple script which when packaged as a Win32App, can be used to deploy any package located in the WinGet public repository automatically to Intune enrolled endpoints.\nThe script can be found on my Github page here. I also have this prepackaged as an IntuneWin package here. Here is the script:\n\u0026lt;#\t.NOTES =========================================================================== Created with: SAPIEN Technologies, Inc., PowerShell Studio 2021 v5.8.195 Created on: 3/7/2022 2:14 PM Created by: Dave Just Organization: Filename: Winget-InstallPackage.ps1 =========================================================================== .DESCRIPTION Installs any package within the WinGet public repository running as SYSTEM. Can be packaged and deployed as a Win32App in Intune Use as base for any install with WinGet. Simply specify the PackageID and log variables. .PARAMETER PackageID Specify the WinGet ID. Use WinGet Search \u0026#34;SoftwareName\u0026#34; to locate the PackageID .EXAMPLE powershell.exe -exectuionpolicy bypass -file Winget-InstallPackage.ps1 -PackageID \u0026#34;Google.Chrome\u0026#34; -Log \u0026#34;ChromeWingetInstall.log\u0026#34; .EXAMPLE powershell.exe -executionpolicy bypass -file Winget-InstallPackage.ps1 -PackageID \u0026#34;Notepad++.Notepad++\u0026#34; -Log \u0026#34;NotepadPlusPlus.log\u0026#34; #\u0026gt; param ( $PackageID, $Log ) # Re-launch as 64bit process (source: https://z-nerd.com/blog/2020/03/31-intune-win32-apps-powershell-script-installer/) $argsString = \u0026#34;\u0026#34; If ($ENV:PROCESSOR_ARCHITEW6432 -eq \u0026#34;AMD64\u0026#34;) { Try { foreach ($k in $MyInvocation.BoundParameters.keys) { switch ($MyInvocation.BoundParameters[$k].GetType().Name) { \u0026#34;SwitchParameter\u0026#34; { if ($MyInvocation.BoundParameters[$k].IsPresent) { $argsString += \u0026#34;-$k \u0026#34; } } \u0026#34;String\u0026#34; { $argsString += \u0026#34;-$k `\u0026#34;$($MyInvocation.BoundParameters[$k])`\u0026#34; \u0026#34; } \u0026#34;Int32\u0026#34; { $argsString += \u0026#34;-$k $($MyInvocation.BoundParameters[$k]) \u0026#34; } \u0026#34;Boolean\u0026#34; { $argsString += \u0026#34;-$k `$$($MyInvocation.BoundParameters[$k]) \u0026#34; } } } Start-Process -FilePath \u0026#34;$ENV:WINDIR\\SysNative\\WindowsPowershell\\v1.0\\PowerShell.exe\u0026#34; -ArgumentList \u0026#34;-File `\u0026#34;$($PSScriptRoot)\\Winget-InstallPackage.ps1`\u0026#34; $($argsString)\u0026#34; -Wait -NoNewWindow } Catch { Throw \u0026#34;Failed to start 64-bit PowerShell\u0026#34; } Exit } #region HelperFunctions function InstallWingetAsSystem # Install WinGet as logged on user by creating a scheduled task { $script = @\u0026#39; $releases_url = \u0026#34;https://api.github.com/repos/microsoft/winget-cli/releases/latest\u0026#34; [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 $releases = Invoke-RestMethod -uri \u0026#34;$($releases_url)\u0026#34; $latestRelease = $releases.assets | Where { $_.browser_download_url.EndsWith(\u0026#34;msixbundle\u0026#34;) } | Select -First 1 Add-AppxPackage -Path \u0026#39;https://aka.ms/Microsoft.VCLibs.x64.14.00.Desktop.appx\u0026#39; Add-AppxPackage -Path $latestRelease.browser_download_url \u0026#39;@ if (!(test-path \u0026#34;$env:systemdrive\\automation\u0026#34;)) { mkdir \u0026#34;$env:systemdrive\\automation\u0026#34; } $script | out-file \u0026#34;$env:systemdrive\\automation\\script.ps1\u0026#34; $action = New-ScheduledTaskAction -Execute \u0026#34;powershell.exe\u0026#34; -Argument \u0026#34;-executionpolicy bypass -WindowStyle minimized -file %HOMEDRIVE%\\automation\\script.ps1\u0026#34; $trigger = New-ScheduledTaskTrigger -AtLogOn $principal = New-ScheduledTaskPrincipal -UserId (Get-CimInstance -ClassName Win32_ComputerSystem | Select-Object -expand UserName) $task = New-ScheduledTask -Action $action -Trigger $trigger -Principal $principal Register-ScheduledTask RunScript -InputObject $task Start-ScheduledTask -TaskName RunScript Start-Sleep -Seconds 120 Unregister-ScheduledTask -TaskName RunScript -Confirm:$false Remove-Item C:\\automation\\script.ps1 $Global:Winget = gci \u0026#34;$env:programfiles\\WindowsApps\u0026#34; -Recurse -File | where { $_.name -like \u0026#34;AppInstallerCLI.exe\u0026#34; -or $_.name -like \u0026#34;Winget.exe\u0026#34; } | select -ExpandProperty fullname } function Write-Log($message) #Log script messages to temp directory { $LogMessage = ((Get-Date -Format \u0026#34;MM-dd-yy HH:MM:ss \u0026#34;) + $message) Out-File -InputObject $LogMessage -FilePath \u0026#34;$Env:Temp\\$Log\u0026#34; -Append -Encoding utf8 } function WingetTempDownload # Download WinGet from blob storage if unable to install { $WebClient = New-Object System.Net.WebClient try { $WebClient.DownloadFile(\u0026#39;https://djstorage2.blob.core.windows.net/scriptsupport/WinGet.zip\u0026#39;, \u0026#34;$env:Temp\\WinGet.zip\u0026#34;) $WebClient.Dispose() } Catch { Write-Log $error exit 1 } try { mkdir \u0026#34;$env:TEMP\\WingetTemp\u0026#34; -Force Expand-Archive \u0026#34;$env:TEMP\\WinGet.zip\u0026#34; -destination \u0026#34;$Env:Temp\\WingetTemp\u0026#34; -Force -ErrorAction \u0026#39;Stop\u0026#39; $global:Winget = \u0026#34;$Env:TEMP\\WinGetTemp\\Winget\\AppInstallerCLI.exe\u0026#34; } Catch { Write-Log $Error exit 1 } $WebClient.Dispose() } function WingetRun { param ( $PackageID, $RunType ) \u0026amp; $Winget $RunType --id $PackageID --source Winget --silent --accept-package-agreements --accept-source-agreements } function Install-VisualC { $url = \u0026#39;https://aka.ms/vs/17/release/vc_redist.x64.exe\u0026#39; $WebClient = New-Object System.Net.WebClient $WebClient.DownloadFile(\u0026#39;https://aka.ms/vs/17/release/vc_redist.x64.exe\u0026#39;, \u0026#34;$env:Temp\\vc_redist.x64.exe\u0026#34;) $WebClient.Dispose() start-process \u0026#34;$env:temp\\vc_redist.x64.exe\u0026#34; -argumentlist \u0026#34;/q /norestart\u0026#34; -Wait } function Get-RegUninstallKey { param ( [string]$DisplayName ) $ErrorActionPreference = \u0026#39;Continue\u0026#39; #$UserSID = (New-Object -ComObject Microsoft.DiskQuota).TranslateLogonNameToSID((Get-CimInstance -Class Win32_ComputerSystem).Username) $uninstallKeys = \u0026#34;registry::HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\u0026#34;, \u0026#34;registry::HKLM\\Software\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\u0026#34; $softwareTable = @() foreach ($key in $uninstallKeys) { $softwareTable += Get-Childitem $key | Get-ItemProperty | where displayname | Sort-Object -Property displayname } if ($DisplayName) { $softwareTable | where displayname -Like \u0026#34;*$DisplayName*\u0026#34; } else { $softwareTable | Sort-Object -Property displayname -Unique } } #endregion HelperFunctions #region Script $VisualC = Get-RegUninstallKey -DisplayName \u0026#34;Microsoft Visual C++ 2015-2022 Redistributable (x64)\u0026#34; $loggedOnUser = (gcim win32_computersystem).username # Get path for Winget executible $Winget = gci \u0026#34;$env:ProgramFiles\\WindowsApps\u0026#34; -Recurse -File | where { $_.name -like \u0026#34;AppInstallerCLI.exe\u0026#34; -or $_.name -like \u0026#34;Winget.exe\u0026#34; } | select -ExpandProperty fullname # If there are multiple versions, select latest if ($Winget.count -gt 1) { $Winget = $Winget[-1] } # If Visual C++ Redist. not installed, install it if (!$VisualC){ Write-Log -message \u0026#34;Visual C++ X64 not found. Attempting to install\u0026#34; try { Install-VisualC } Catch [System.InvalidOperationException]{ Write-Log -message \u0026#34;Error installing visual c++ redistributable. Attempting install once more\u0026#34; Start-Sleep -Seconds 5 Install-VisualC } Catch { Write-Log -message \u0026#34;Failed to install visual c++ redistributable!\u0026#34; Write-Log -message $_ exit 1 } $VisualC = Get-RegUninstallKey -DisplayName \u0026#34;Microsoft Visual C++ 2015-2022 Redistributable (x64)\u0026#34; if (!$VisualC){Write-Log -message \u0026#34;Visual C++ Redistributable not found!\u0026#34; ; exit 1} else {Write-Log -message \u0026#34;Successfully installed Microsoft Visual C++ 2015-2022 Redistributable (x64)\u0026#34;} } # If Winget is not found, attempt to install it, or download copy from baselob storage if (!$Winget) { if ($loggedOnUser) { Write-Log -message \u0026#34;Attempting to install Winget as System under $($loggedOnUser)\u0026#34; InstallWingetAsSystem # If more than one version of Winget, select the latest if ($Winget.count -gt 1) { $Winget = $Winget[-1] } # If WinGet is not found, download copy from Blob storage if (!$Winget){Write-Log -message \u0026#34;Downloading winget from blob storage\u0026#34; ; WingetTempDownload } try { Write-Log -message \u0026#34;Winget varibale $($winget)\u0026#34; $Install = WingetRun -RunType install -PackageID $PackageID Write-Log $Install } Catch { Write-Log $error[0] exit 1 } } else { try { Write-Log \u0026#34;Winget not found, attempting to download now to $($env:TEMP)\u0026#34; WingetTempDownload try { $Install = WingetRun -RunType install -PackageID $PackageID Write-Log $Install } Catch { Write-Log $error exit 1 } } Catch { Write-Log \u0026#34;Unable to initialize Winget. Exiting\u0026#34; Write-Output $Error exit 1 } } } else { Write-Log \u0026#34;Winget found at $($Winget)\u0026#34; $Install = WingetRun -RunType install -PackageID $PackageID Write-Log $Install } #endregion Upload the package to Intune as a Win32App. For the install command, enter the following. Edit the PackageID and Log parameters as needed. Use the exact WinGet package ID.\npowershell.exe -executionpolicy bypass -file Winget-InstallPackage.ps1 -PackageID \u0026#34;Google.Chrome\u0026#34; -Log \u0026#34;ChromeWingetInstall.log\u0026#34; To find the ID, open PowerShell or CMD and run \u0026ldquo;Winget Search SoftwareName\u0026rdquo;. In the output you will see the ID field.\nThe uninstall command is going to be dependent on the particular software. You can usually find the uninstall command in the uninstall registry key. You can use this PowerShell function I wrote to grab the uninstall string. Look for a quiet uninstall parameter, you may need to do some searching.\nfunction Get-RegUninstallKey { param ( [string]$DisplayName ) $ErrorActionPreference = \u0026#39;Continue\u0026#39; $uninstallKeys = \u0026#34;registry::HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\u0026#34;, \u0026#34;registry::HKLM\\Software\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\u0026#34; $softwareTable =@() foreach ($key in $uninstallKeys) { $softwareTable += Get-Childitem $key | Get-ItemProperty | where displayname | Sort-Object -Property displayname } if ($DisplayName) { $softwareTable | where displayname -Like \u0026#34;*$DisplayName*\u0026#34; } else { $softwareTable | Sort-Object -Property displayname -Unique } } And running this for Google Chrome we get the Msiexec uninstall command. Simply add /qn /norestart at the end of the command and enter that into Intune as the Uninstall command.\nOr if you don\u0026rsquo;t care really about uninstalling, you can just type anything like \u0026ldquo;Uninstall\u0026rdquo;.\nFinally for the detection script, I like to use the same Get-RegUinstallKey function to look for the presence of an uninstall key for the software to determine if it is installed. You can find the detection script here and Ill also include it below:\n\u0026lt;#\t.NOTES =========================================================================== Created with: SAPIEN Technologies, Inc., PowerShell Studio 2021 v5.8.195 Created on: 3/7/2022 2:14 PM Created by: Dave Just Organization: Filename: WingetInstallDetection.ps1 =========================================================================== .DESCRIPTION Simple Win32App detection script. Detects the presence of an uninstall key matching the displayname of the variable $SoftwareName. If a key is matched, return to Intune that the software is installed. .EXAMPLE $SoftwareName = \u0026#39;Chrome\u0026#39; # Search for an uninstall key with Displayname \u0026#39;Chrome\u0026#39; for Google Chrome #\u0026gt; # Edit the software displayname below $SoftwareName = \u0026#39;\u0026#39; function Get-RegUninstallKey { param ( [string]$DisplayName ) $ErrorActionPreference = \u0026#39;Continue\u0026#39; #$UserSID = (New-Object -ComObject Microsoft.DiskQuota).TranslateLogonNameToSID((Get-CimInstance -Class Win32_ComputerSystem).Username) $uninstallKeys = \u0026#34;registry::HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\u0026#34;, \u0026#34;registry::HKLM\\Software\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\u0026#34; $softwareTable = @() foreach ($key in $uninstallKeys) { $softwareTable += Get-Childitem $key | Get-ItemProperty | where displayname | Sort-Object -Property displayname } if ($DisplayName) { $softwareTable | where displayname -Like \u0026#34;*$DisplayName*\u0026#34; } else { $softwareTable | Sort-Object -Property displayname -Unique } } $UninstallKey = Get-RegUninstallKey -DisplayName $SoftwareName if ($UninstallKey) { Write-Output \u0026#34;$($SoftwareName) is installed\u0026#34; exit 0 } else { exit 1 } And that\u0026rsquo;s it! Now you don\u0026rsquo;t need to worry about uploading the latest installer for commonly installed software. WinGet will always install the latest version.\n", 
            "url": "\/post\/intune-install-software-with-winget\/"
        },
        
        
        
        "\/post\/intune-for-macos-configure-macos-vm\/": {
            
            "title": "Configuring Intune for macOS part 1 - Setup a macOS VM",
            "tags": ["O365","Intune","macOS",],
            "content": "Premise\nOne of my clients has an Apple only environment. The client was previously managed with Jamf. Jamf is a great MDM platform for Apple devices and works really well however there are some downsides. First, the cost of Jamf is quite high, also while Jamf does support M365 condtional access and SSO with M365, it requires a bit more configuration than Intune does. My client was already paying for Enterprise mobility and Security licensing through M365 with Defender ATP for Endpoint so why not take advantage of the included Intune licensing? I feel Intune has matured enough to fully manage the MDM needs for Apple devices so lets dive into getting started!\nGetting Started - Setup a macOS VM\nMy first hurdle to overcome was the need for a test environment. I like to fully test configuration scenarios before deploying anything to production. I however do not own any Apple hardware, and I did not want to shell out ~$600 for a current mac mini. In comes the OSX-KVM project on Github. This project makes it super simple to setup a macOS VM. All you will need is a PC with either an Intel or AMD processor that supports AVX2 and a compatible Linux distribution. I have personally tested this on both Pop!_OS 21.10 on my PC and Ubuntu 21.10 on my home ESXi server with Ubuntu 21.10 using nested virtualization. You could even set this up inside the live boot environment of Ubuntu/pop!_OS without even needing to install the OS on your system, though you would want a large enough flash drive to store all the files, at least 64GB.\nIf you only have one PC and you don\u0026rsquo;t want to do a traditional dual boot, I recommend just picking up an additional 120GB SATA SSD. Install your Linux distro to that and simply use your EFI\u0026rsquo;s boot menu to select which hard drive to boot off of, either Windows or Linux. Just be careful when installing your Linux distro to not overwrite your Windows installation! To be on the safe side, just unplug your current boot hard drive with Windows before installing Linux.\nFor this demo, I will be installing Ubuntu 21.10 os ESXi. Create a new VM, Select Linux as the guest OS and Ubuntu Linux 64bit as the OS version. Doing this will automate the vmware tools installation.\nFirst, download the Ubuntu installation ISO. Once downloaded, go ahead and upload the ISO to your ESXi datastore. Select storage, the data store, click \u0026ldquo;Datastore Browser\u0026rdquo;, then select upload.\nOn the settings page, I recommend giving the VM at 6 cpus and 12GB of ram and 120GB of storage. You could probably skirt by with less but just be aware your macOS VM will be very slow. Expand the CD/DVD options, and connect your Ubuntu ISO\nBefore you power on the VM, edit the settings. Expand CPU, and enable Hardware virtualization\nUnder VM Options, expand Boot Options. Change the firmware setting to EFI. Now, go ahead and boot the VM. Select Install Ubuntu, and just continue through the prompts with default settings. The installation is fairly quick.\nOnce you are logged into the desktop, right click on the desktop and select desktop settings. Change the resolution to 1920x1080 (or whatever you prefer).\nGo ahead and install any OS updates and reboot. Open up the OSX-KVM project on GitHub and follow the instructions there for setting up your VM.\nHere are a few tips that are not explained in the github readme:\nThe virtual machine defaults to 3GB of ram which really is not enough for macOS. You can add additonal ram by editing the. Run the following command to open the OpenCore-Boot script in gedit\ngedit ~/OSX-KVM/OpenCore-Boot.sh Edit the line ALLOCATED_RAM. I recommend setting this to 8GB (8192 MiB)\nOnce you have the VM booted and and logged in, I strongly suggest disabling the sleep / screen blank option in macOS power settings.\nNow we have a VM ready for testing. See part 2 for BYOD enrollment and configuration profile setup.\rHelpful macOS Resources\r", 
            "url": "\/post\/intune-for-macos-configure-macos-vm\/"
        },
        
        
        
        "\/post\/use-powershell-to-get-the-weather-report\/": {
            
            "title": "PowerShell Project - Get the Weather report",
            "tags": ["PowerShell","restAPI",],
            "content": "I thought it would be a fun project to create a PowerShell function which would get the Weather forecast for a specified location.\nI started searching online for free Weather REST APIs which I could query for the forecast. I found api.weather.gov which has a completely free and open REST API with complete documentation API Web Service (weather.gov). Checking the documentation, the REST endpoint to query the forecast is https://api.weather.gov/gridpoints/{office}/{grid\rX},{grid Y}/forecast. To find the grid points, we can use the /points endpoint with latitude and longitude co-ordinates https://api.weather.gov/points/{latitude},{longitude}\r. I found a free web service which will provide latitude and longitude based on zip code https://api.promaptools.com/service/us/zip-lat-lng/get/?zip=$zipcode\u0026amp;key=17o8dysaCDrgv1c\r.\nAfter fiddling around with Invoke-RestMethod to get the data I wanted, I came up with this function in PowerShell.\nfunction Get-WeatherForecast { param ( [parameter(mandatory=$true)] [string]$zipcode ) #region Weather Variables #Get Lattitude and Longitude for your zip code $getLatLong = Invoke-restmethod -uri \u0026#34;https://api.promaptools.com/service/us/zip-lat-lng/get/?zip=$zipcode\u0026amp;key=17o8dysaCDrgv1c\u0026#34; | select -ExpandProperty output #Get weather forecast endpoint for your zipcode $getPoints = Invoke-RestMethod -uri \u0026#34;https://api.weather.gov/points/$($getLatLong.latitude),$($getLatLong.longitude)\u0026#34; #Get 7 day weather forecast $weatherGet = Invoke-RestMethod -Uri $getPoints.properties.forecast #Get todays date. Manipulate string to match JSON date object returned from api.weather.gov $TodayManipulate = ((get-date).ToShortDateString() -replace \u0026#39;/\u0026#39;,\u0026#39;-\u0026#39;) -split \u0026#39;-\u0026#39; $today = \u0026#34;$($TodayManipulate[2] + \u0026#39;-\u0026#39; + $TodayManipulate[0] + \u0026#39;-\u0026#39; + $TodayManipulate[1])*\u0026#34; # Do the same for tomorrows date $TomorrowManipulate = (((get-date).AddDays(1)).ToShortDateString() -replace \u0026#39;/\u0026#39;,\u0026#39;-\u0026#39;) -split \u0026#39;-\u0026#39; $tomorrow = \u0026#34;$($TomorrowManipulate[2] + \u0026#39;-\u0026#39; + $TomorrowManipulate[0] + \u0026#39;-\u0026#39; + $TomorrowManipulate[1])*\u0026#34; # Get today and tomorrows forecasted temperatures $todaysTemp = Invoke-RestMethod -Uri \u0026#39;https://api.weather.gov/gridpoints/LWX/102,88\u0026#39; | select -ExpandProperty properties | select -ExpandProperty temperature | select -ExpandProperty values | select -ExcludeProperty values | where validtime -like \u0026#34;$($today)\u0026#34; | sort value $tomorrowsTemp = Invoke-RestMethod -Uri \u0026#39;https://api.weather.gov/gridpoints/LWX/102,88\u0026#39; | select -ExpandProperty properties | select -ExpandProperty temperature | select -ExpandProperty values | select -ExcludeProperty values | where validtime -like \u0026#34;$($tomorrow)\u0026#34; | sort value # Convert temps to farenheit $TodaysTempF = $todaysTemp | select @{n=\u0026#34;Temp\u0026#34;;e={$_.value | foreach {[int]($_ * 1.8) + 32}}} $tomorrowsTempF = $tomorrowsTemp | select @{n=\u0026#34;Temp\u0026#34;;e={$_.value | foreach {[int]($_ * 1.8) + 32}}} # Get low and high temperatures, selecting by index of array $LowTempToday = ($TodaysTempF.Temp)[0] $LowTempTomorrow = ($tomorrowsTempF.Temp)[0] $HighTempToday = ($TodaysTempF.Temp)[-1] $HighTempTomorrow = ($tomorrowsTempF.Temp)[-1] # Filter 7 day forecast for today and tomorrows forecast $forecast = $weatherGet | select -ExpandProperty properties | select -ExpandProperty periods | where number -eq 1 $tomorrowsForecast = ($weatherGet | select -ExpandProperty properties | select -ExpandProperty periods | where startTime -like $tomorrow)[0] #endregion Write-Host \u0026#34;Forecast for $((Get-Date).ToShortDateString())\u0026#34; -foregroundcolor Green -backgroundcolor Black Write-Host \u0026#34;Todays Low Temperature: $($LowTempToday)\u0026#34; Write-host \u0026#34;Todays High Temperature: $($HighTempToday)\u0026#34; Write-Host \u0026#34;Detailed Forecast: `n$($forecast.detailedForecast)\u0026#34; -ForegroundColor Green -BackgroundColor Black write-host \u0026#34;`nTomorrows Low Temperature: $($LowTempTomorrow)\u0026#34; write-host \u0026#34;Tomorrows High Temperature: $($HighTempTomorrow)\u0026#34; Write-Host \u0026#34;`nTomorrows Forecast:`n$($tomorrowsForecast.detailedForecast)\u0026#34; -foregroundcolor Green -BackgroundColor Black } All in all, this project took about an hour. I have since combined it with a scheduled task on one of my VM\u0026rsquo;s to send me a daily email with the forecast using the Microsoft Graph SendMail API. For a tutorial on sending mail using Graph, I recommend checking out the tech guy blog Send Mail with PowerShell and Microsoft Graph API - TechGuy\n", 
            "url": "\/post\/use-powershell-to-get-the-weather-report\/"
        },
        
        
        
        "\/tags\/restapi\/": {
            
            "title": "restAPI",
            "tags": [],
            "content": "", 
            "url": "\/tags\/restapi\/"
        },
        
        
        
        "\/post\/o365-license-report-with-friendly-names\/": {
            
            "title": "Export O365 User License Report with friendly names",
            "tags": ["PowerShell","Intune",],
            "content": "I was recently tasked with exporting a report for a client that detailed all users, their location and license assignment in Office 365. I knew the best way to get the job done was by writing a PowerShell script.\nI did a quick search online and found lots of examples, however all the examples I found were using the deprecated \u0026ldquo;Microsoft Online\u0026rdquo; / MSOL PS module. I wanted to use the Azure AD module instead so I played around a bit to get the output I wanted.\nThe boss also wanted the export to have the \u0026ldquo;Friendly\u0026rdquo; license names not the esoteric sku names that Microsoft uses on the backed. I found this handy article here that lists sku names with their current product names. So a quick hashtable will take care of that for us.\nFirst problem, how do we come up with what licenses are assigned to each user? First I connected to AzureAD then ran\nGet-AzureADUser | Get-Member -membertype Properties One of the first properties I noticed was \u0026ldquo;Assigned Licenses\u0026rdquo;, so I thought great! Lets try outputting that. Next command I ran:\nGet-AzureADUser -objectid dave@justgeeks.co | select userprincipalname,assignedlicenses | Format-Table -AutoSize -Wrap To my dismay, this was the output:\nNot exactly what I had in mind. Ok, we need to do a little conversion. I found this cmdlet \u0026ldquo;Get-AzureADSubscribedSku\u0026rdquo; which gives this output:\nOk cool, I can work with that. Looks like the ObjectID is TenantID_SkuID. SkuPartNumber is the actual Sku name.\nHere is the script I came up with\n# Get Tenant ID $TenantID = Get-AzureADTenantDetail | select -ExpandProperty ObjectID # Get list of licensed users $users = Get-AzureADUser -all $true | where assignedlicenses -ne $null # Hash table to convert sku names to freindly license names $skus = @{ \u0026#34;AAD_PREMIUM\u0026#34; = \u0026#34;AZURE ACTIVE DIRECTORY PREMIUM P1\u0026#34; \u0026#34;AAD_PREMIUM_P2\u0026#34;\t= \u0026#34;Azure Active Directory Premium P2\u0026#34;; \u0026#34;INTUNE_A\u0026#34;\t= \u0026#34;Intune\u0026#34;; \u0026#34;O365_BUSINESS_ESSENTIALS\u0026#34; = \u0026#34;Microsoft 365 Business Basic\u0026#34;; \u0026#34;SPE_E3\u0026#34;\t= \u0026#34;Microsoft 365 E3\u0026#34;; \u0026#34;SPE_E5\u0026#34;\t= \u0026#34;Microsoft 365 E5\u0026#34;; \u0026#34;THREAT_INTELLIGENCE\u0026#34;\t= \u0026#34;Microsoft Defender for Office 365 (Plan 2)\u0026#34;; \u0026#34;POWERAPPS_VIRAL\u0026#34;\t= \u0026#34;Microsoft Power Apps Plan 2 Trial\u0026#34;; \u0026#34;FLOW_FREE\u0026#34;\t= \u0026#34;Microsoft Power Automate Free\u0026#34;; \u0026#34;TEAMS_EXPLORATORY\u0026#34;\t= \u0026#34;Microsoft Teams Exploratory\u0026#34;; \u0026#34;DESKLESSPACK\u0026#34;\t= \u0026#34;Office 365 F3\u0026#34;; \u0026#34;POWER_BI_STANDARD\u0026#34;\t= \u0026#34;Power BI (free)\u0026#34;; \u0026#34;PROJECTPROFESSIONAL\u0026#34;\t= \u0026#34;Project Plan 3\u0026#34;; \u0026#34;VISIOCLIENT\u0026#34;\t= \u0026#34;Visio Plan 2\u0026#34;; \u0026#34;WINDOWS_STORE\u0026#34;\t= \u0026#34;WINDOWS STORE FOR BUSINESS\u0026#34;; \u0026#34;SHAREPOINTSTORAGE\u0026#34;\t= \u0026#34;SharePoint Online Storage\u0026#34;; \u0026#34;RIGHTSMANAGEMENT\u0026#34; = \u0026#34;AZURE INFORMATION PROTECTION PLAN 1\u0026#34; \u0026#34;RMSBASIC\u0026#34;\t= \u0026#34;Rights Management Basic\u0026#34;; \u0026#34;MICROSOFT_BUSINESS_CENTER\u0026#34; = \u0026#34;Microsoft Business Center\u0026#34;; \u0026#34;MICROSOFT 365 APPS FOR BUSINESS\u0026#34; = \u0026#34;SMB_BUSINESS\u0026#34; } $i = 1 $UserLicenseList = [System.Collections.Generic.List[PsObject]]::new() foreach ($user in $users) { Write-progress -activity \u0026#34;Processing\u0026#34; -Status \u0026#34;Working on: $($user.displayname)\u0026#34; -PercentComplete (($i / $users.count) * 100) $licenses = ($user).assignedlicenses.skuid | foreach { (Get-AzureADSubscribedSku -ObjectID ($($TenantID) + \u0026#39;_\u0026#39; + $_)).skupartnumber } | foreach { $skus[$_] } $UserLicenseList.add([PSCustomObject]@{ DisplayName = $user.displayname UserPrincipalName = $user.UserPrincipalName StreetAddress = $user.StreetAddress licenses = $licenses -join \u0026#39;,\u0026#39; }) $i++ } Let\u0026rsquo;s break it down.\n# Get Tenant ID $TenantID = Get-AzureADTenantDetail | select -ExpandProperty ObjectID # Get list of licensed users $users = Get-AzureADUser -all $true | where assignedlicenses -ne $null First, I get the tenant ID since I know that the tenant ID is part of the AzureADSubscribedSku object ID. Then I get the list of licensed users.\n# Hash table to convert sku names to freindly license names $skus = @{ \u0026#34;AAD_PREMIUM\u0026#34; = \u0026#34;AZURE ACTIVE DIRECTORY PREMIUM P1\u0026#34; \u0026#34;AAD_PREMIUM_P2\u0026#34;\t= \u0026#34;Azure Active Directory Premium P2\u0026#34;; \u0026#34;INTUNE_A\u0026#34;\t= \u0026#34;Intune\u0026#34;; \u0026#34;O365_BUSINESS_ESSENTIALS\u0026#34; = \u0026#34;Microsoft 365 Business Basic\u0026#34;; \u0026#34;SPE_E3\u0026#34;\t= \u0026#34;Microsoft 365 E3\u0026#34;; \u0026#34;SPE_E5\u0026#34;\t= \u0026#34;Microsoft 365 E5\u0026#34;; \u0026#34;THREAT_INTELLIGENCE\u0026#34;\t= \u0026#34;Microsoft Defender for Office 365 (Plan 2)\u0026#34;; \u0026#34;POWERAPPS_VIRAL\u0026#34;\t= \u0026#34;Microsoft Power Apps Plan 2 Trial\u0026#34;; \u0026#34;FLOW_FREE\u0026#34;\t= \u0026#34;Microsoft Power Automate Free\u0026#34;; \u0026#34;TEAMS_EXPLORATORY\u0026#34;\t= \u0026#34;Microsoft Teams Exploratory\u0026#34;; \u0026#34;DESKLESSPACK\u0026#34;\t= \u0026#34;Office 365 F3\u0026#34;; \u0026#34;POWER_BI_STANDARD\u0026#34;\t= \u0026#34;Power BI (free)\u0026#34;; \u0026#34;PROJECTPROFESSIONAL\u0026#34;\t= \u0026#34;Project Plan 3\u0026#34;; \u0026#34;VISIOCLIENT\u0026#34;\t= \u0026#34;Visio Plan 2\u0026#34;; \u0026#34;WINDOWS_STORE\u0026#34;\t= \u0026#34;WINDOWS STORE FOR BUSINESS\u0026#34;; \u0026#34;SHAREPOINTSTORAGE\u0026#34;\t= \u0026#34;SharePoint Online Storage\u0026#34;; \u0026#34;RIGHTSMANAGEMENT\u0026#34; = \u0026#34;AZURE INFORMATION PROTECTION PLAN 1\u0026#34; \u0026#34;RMSBASIC\u0026#34;\t= \u0026#34;Rights Management Basic\u0026#34;; \u0026#34;MICROSOFT_BUSINESS_CENTER\u0026#34; = \u0026#34;Microsoft Business Center\u0026#34;; \u0026#34;MICROSOFT 365 APPS FOR BUSINESS\u0026#34; = \u0026#34;SMB_BUSINESS\u0026#34; } Then I created a hashtable to map the sku names to their friendly names.\n$i = 1 $UserLicenseList = [System.Collections.Generic.List[PsObject]]::new() foreach ($user in $users) { Write-progress -activity \u0026#34;Processing\u0026#34; -Status \u0026#34;Working on: $($user.displayname)\u0026#34; -PercentComplete (($i / $users.count) * 100) $licenses = ($user).assignedlicenses.skuid | foreach { (Get-AzureADSubscribedSku -ObjectID ($($TenantID) + \u0026#39;_\u0026#39; + $_)).skupartnumber } | foreach { $skus[$_] } Then the fun part, create a foreach loop.\nFor each user, create a progress bar to display the progress for processing each users licenses.\nFor each user, Transform the users Assigned Licenses / SkuID into the actual Sku name by feeding it in Get-AzureADSubscribedSku.\nFor each skuid, add the tenantID as Get-AzureADSubscribedSku is expecting \u0026ldquo;TenantID_SkuID\u0026rdquo;, then putll out the SkuPartNumber which was the sku name.\nThen take the Sku name and transform it to the friendly name by using the corresponding index of the hashtable.\n$licenses = ($user).assignedlicenses.skuid | foreach { (Get-AzureADSubscribedSku -ObjectID ($($TenantID) + \u0026#39;_\u0026#39; + $_)).skupartnumber } | foreach { $skus[$_] $UserLicenseList.add([PSCustomObject]@{ DisplayName = $user.displayname UserPrincipalName = $user.UserPrincipalName StreetAddress = $user.StreetAddress licenses = $licenses -join \u0026#39;,\u0026#39; }) $i++ Finally, fill a list with the properties I want for the report. Notice I join the licenses for each user into a single string so that when I go to export the report the licenses will display correctly if the user has multiple assigned. Otherwise the output would just show [System.Object] as the output would be an array rather than a single string.\nThen increment our counter by 1, $i being the counter.\nJust to be extra diligent, lets get the total license list and count for the tenant:\n$TotalLicenses = Get-AzureADSubscribedSku | Select -Property SkuPartNumber, @{ n = \u0026#34;Sku\u0026#34;; e = { $skus[$_.SkuPartNumber] } }, @{ n = \u0026#34;Used\u0026#34;; e = { $_.ConsumedUnits } }, @{ n = \u0026#34;Total\u0026#34;; e = { $_.prepaidunits.enabled } } Now to export everything to an excel spreadsheet cause we are fancy, no simple csv here! Using the module ImportExcel:\n# Export to Excel Spreadsheet $TotalLicenses | Export-Excel -Autosize .\\UserLicenseReport.xlsx -TableName \u0026#34;TotalLicenses\u0026#34; -Worksheetname \u0026#34;TotalLicenses\u0026#34; $UserLicenseList | Export-Excel -Autosize \\UserLicenseReport.xlsx -TableName \u0026#34;UserLicenseDetails\u0026#34; -Worksheetname \u0026#34;UserLicenseReport\u0026#34; Here we create one excel spreadsheet \u0026ldquo;UserLicensesReport.xlsx\u0026rdquo; with two worksheets \u0026ldquo;TotalLicenses\u0026rdquo; and \u0026ldquo;UserLicenseDetails\u0026rdquo;. Each report being an autosized table on each worksheet.\nAnd that\u0026rsquo;s it! In the next article, I will show how to automate these type of reports using certificate based authentication.\n", 
            "url": "\/post\/o365-license-report-with-friendly-names\/"
        },
        
        
        
        "\/post\/create-power-automate-flows-with-powershell-reports\/": {
            
            "title": "Collect data in an Azure Table with Power Automate and PowerShell",
            "tags": ["O365","Intune","Power Automate",],
            "content": "If there is one thing I love it is automation. If you are a systems administrator, you have probably at some point needed to create some reports using PowerShell. Usually you would do this manually and export this to a CSV them hand off the report in an email or through SharePoint ect. But how can we automate this process?\nWhile you could run PowerShell scripts as a scheduled task to fire off an email which is quick and dirty. But is there a more elegant solution? In comes Power Automate Flows.\nFirst I am going to create an Azure Storage Table to hold our report data. Why? While this is not 100% necessary, I like the idea of retaining the data for future use, or wowing the client/boss with a PowerBi report. Log into Azure and create a v2 storage account. Go to \u0026ldquo;Tables\u0026rdquo; and create a table. Name it whatever you desire.\nHere I have created a couple tables to hold different reports.\nNow lets log into Power Automate and create our flow.\nSelect \u0026ldquo;New Flow\u0026rdquo; then \u0026ldquo;Automated Cloud Flow\u0026rdquo;. Click Skip without entering a trigger. We will do this manually\nNow lets create our trigger. We will use \u0026ldquo;When a HTTP request is recieved\u0026rdquo;\nNow we need to generate a JSON schema. To do this run your powershell report. Here is the report I will be using\nConnect-AzureAD $TenantID = Get-AzureADTenantDetail | select -ExpandProperty ObjectID $users = Get-AzureADUser -all $true | where assignedlicenses -ne $null $list = [System.Collections.Generic.List[PsObject]]::new() foreach ($user in $users) { $licenses = ($user).assignedlicenses.skuid | foreach { (Get-AzureADSubscribedSku -ObjectID ($($TenantID) + \u0026#39;_\u0026#39; + $_)).skupartnumber } $lic = $licenses -join \u0026#39; \u0026#39; $licComma = $lic -replace \u0026#39; \u0026#39;, \u0026#39;,\u0026#39; $list.add([PSCustomObject]@{ Name = $user.displayname Email = $user.UserPrincipalName licenses = $licComma StreetAddress = $user.streetaddress }) } This report will generate a list of licensed users with their license details and location. To generate our sample JSON payload, just convert the output to JSON:\n$list | ConvertTo-Json Grab the output and slap it into the sample JSON payload. Heres what the schema looks like this:\n{\r\u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;,\r\u0026#34;items\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;,\r\u0026#34;properties\u0026#34;: {\r\u0026#34;Name\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r},\r\u0026#34;Email\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r},\r\u0026#34;licenses\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r},\r\u0026#34;StreetAddress\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r}\r},\r\u0026#34;required\u0026#34;: [\r\u0026#34;Name\u0026#34;,\r\u0026#34;Email\u0026#34;,\r\u0026#34;licenses\u0026#34;,\r\u0026#34;StreetAddress\u0026#34;\r]\r}\r} Now Click next step. Search for \u0026ldquo;Azure Table Storage\u0026rdquo;. Next, setup the connection.\nSet the connection name to something descriptive. The Storage account name is the exact name as its displayed on your account. The storage key is found under Settings / Access Keys\nNext you\u0026rsquo;ll be asked to enter a partition Key, Row Key and Entity. For parition key we will use partition1 (this can be anything you want). For row key we will use \u0026ldquo;Name\u0026rdquo;. For entity select \u0026ldquo;Current Item\u0026rdquo;\nAt this point our flow is good enough to get data into our table. Go ahead and click Save.\nOnce saved, click on the first step \u0026ldquo;When a HTTP request is received\u0026rdquo;. Copy the HTTP Post URL.\nNow, over in our script lets add what we need to POST the data. We need to generate a header and use invoke rest method:\n$header = @{ \u0026#39;Content-Type\u0026#39; = \u0026#34;application/json\u0026#34; } $flowheader = $list $flow = \u0026#34;https://prod-133.westus.logic.azure.com_ect\u0026#34; Invoke-RestMethod -Method Post -Body $($flowheader | ConvertTo-Json -Compress) -uri $flow -Headers $header Our header specifies that we are sending \u0026ldquo;application/json\u0026rdquo; data. If we do not include this, our POST operation will fail. The uri parameter of invoke rest method is the URL we copied from our first flow step.\nOk to test we just run our entire script. You can check My flows to see if the status was a success.\nNow go over to your Azure storage account. Use the Storage explorer to confirm the table was filled.\nNow we see it was a success! Our table is filled with the output of our PS script. We can create more steps in our flow to take this data and post it to teams, send an email, upload to SharePoint ect.\nI will quickly demo how to send this to a email as an HTML table. Lets go back to our flow and add some more steps. Select New Step and add \u0026ldquo;Get Entities\u0026rdquo;\nIf you want to filter based on property criteria, you can use and OData filter query. An example would be StreetAddress eq '1234 Fake Street'\nThis query would only output users with the street address parameter of \u0026lsquo;1234 Fake Street\u0026rsquo;.\nSelect New Step and use \u0026ldquo;Initialize Variable\u0026rdquo;. Set name to \u0026lsquo;Table\u0026rsquo;, type to \u0026lsquo;Array\u0026rsquo;. Value is \u0026lsquo;Get entities result list of entities\u0026rsquo; from our dynamic content\nNext, we will create an HTML table. From use the dynamic content of the output from our array \u0026ldquo;Table\u0026rdquo;\nThe next step is optional. If you only want to fill certain properties from the array to our HTML table, create a step \u0026ldquo;Data operation - Select\u0026rdquo;\nexample:\nFrom - Table Map : Name | item()?[\u0026lsquo;Name\u0026rsquo;]\nMap : Email | item()?[\u0026lsquo;Email\u0026rsquo;]\nInput the selection values inter the expression field as shown:\nLast we will generate an email with the HTML table we created.\nCreate a new step \u0026ldquo;Send an Email\u0026rdquo;. In body select dynamic content \u0026ldquo;Output\u0026rdquo; . Alternatively you could put the \u0026ldquo;Output\u0026rdquo; in attachments.\nAnd that\u0026rsquo;s it! You should have a good foundation here to create some nifty flows. Combine this with Azure Automation to run the reports on a schedule.\nCredit to the Intune Training youtube channel for their amazing example Using Power Automate Flows to Collect Custom Client Inventory - Part 1\r", 
            "url": "\/post\/create-power-automate-flows-with-powershell-reports\/"
        },
        
        
        
        "\/post\/remove-document-redirection-vpn\/": {
            
            "title": "Remove Document Redirection Policies over VPN",
            "tags": ["PowerShell","Intune",],
            "content": "In today\u0026rsquo;s world of COVID with so many people working from home, more and more organizations are moving to cloud services for file storage. It used to be quite a common practice, at least in my experience to enable folder redirection for users on-prem. Trying to dismantle folder redirection, especially when our users are working remotely can prove to be a challenge. If you have ever attempted to remove a folder redirection GPO, you have undoubtedly discovered folder redirection policies only apply (and remove) at startup/user logon. This can throw a wrench in the works if our users are working remotely. In comes a little PowerShell to the rescue.\nFirst, go into your group policy management editor. Open up the folder redirection policy. Edit the properties for every folder that is being redirected by right clicking on the folder and selecting \u0026ldquo;Properties\u0026rdquo;. Make sure under \u0026ldquo;Policy Removal\u0026rdquo;, \u0026ldquo;Leave the folder in the new location when policy is removed\u0026rdquo; is checked. This way, we have full control over when the folders are redirected back to the user.\nGo ahead and remove your users from the folder redirection policy.\nNext, its time for a little PowerShell magic. We can simply delete the folder redirection registry keys to remove the redirection policy.\n$ErrorActionPreference = \u0026#39;Stop\u0026#39; $UserSID = (New-Object -ComObject Microsoft.DiskQuota).TranslateLogonNameToSID((Get-CimInstance -Class Win32_ComputerSystem).Username) $profilepath = Get-itemproperty registry::\u0026#34;HKU\\$usersid\\Volatile Environment\\\u0026#34; -Name Userprofile | Select-Object -ExpandProperty userprofile $RedPolicy = test-path -Path registry::\u0026#34;HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\\$usersid\\fdeploy\u0026#34; if ($RedPolicy) { Write-Host \u0026#34;Redirection Policy detected, attempting to remove policy\u0026#34; Start-Sleep 2 try { Remove-item registry::\u0026#34;HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\\$usersid\\fdeploy\u0026#34; -Recurse Write-Host \u0026#34;Redirection Policy was successfully removed.\u0026#34; if (!(test-path ($profilepath + \u0026#39;\\Documents\u0026#39;))) {New-Item -ItemType Directory ($profilepath + \u0026#39;\\Documents\u0026#39;)} } Catch{ Write-Host $error -ForegroundColor Red $error | Select-Object * | out-file c:\\windows\\temp\\redscript.log Notepad c:\\windows\\temp\\redscript.log } } Now that the policy is removed you have a couple options to move the folders back locally.\nRemote into the users computer. In file explorer right click on each redirected folder and select \u0026quot;Properties\u0026quot;. Under the location tab, select \u0026quot;Move\u0026quot;. Select the local folder and click ok. The files will be moved from the redirected location to the local location. Depending on the size this can take sometime over VPN.\rIf the folder is quite large, or the user has not connected to VPN for sometime to sync their offline files, we can simply move the local cache. You can do this manually or with a little PowerShell\n#Get User Path $UserSID = (New-Object -ComObject Microsoft.DiskQuota).TranslateLogonNameToSID((Get-CimInstance -ClassName Win32_ComputerSystem).Username) $ProfilePath = Get-Itemproperty registry::\u0026#34;HKU\\$UserSID\\Volatile Environment\u0026#34; | select-object -ExpandProperty \u0026#34;USERPROFILE\u0026#34; $Username = Get-ItemProperty registry::\u0026#34;HKU\\$UserSID\\Volatile Environment\u0026#34; | select-object -ExpandProperty \u0026#34;USERNAME\u0026#34; #Set Permissions on the Client Side Caching folder takeown /a /r /d Y /f \u0026#34;c:\\windows\\csc\u0026#34; $useracl = get-acl $ProfilePath\\desktop Get-Item \u0026#34;c:\\windows\\csc\u0026#34; | Set-Acl -AclObject $userAcl #Move the contents of the redirected folders. $cscdocuments = (GCI \u0026#34;C:\\Windows\\CSC\u0026#34; -Directory -Recurse | where name -like \u0026#34;*Documents*\u0026#34;) Move-Item \u0026#34;$($cscdocuments).fullname\\*\u0026#34; -Destination \u0026#34;C:\\users\\$Username\\Documents\\\u0026#34; -Exclude \u0026#34;$Recycle.bin\u0026#34; -Force Here we take ownership of the client side caching folder then take the ACL of the users Desktop and apply that to the CSC folder so they will have full access. Then we move the contents of the cached My Documents folder to C:\\Users\\Username\\Documents excluding the recycle bin.\nDo this process for each redirected folder. Be careful and make sure the cached folders are up to date and the user knows you are moving these folders.\nAnd that\u0026rsquo;s it! Tame folder redirection with a little PS.\n", 
            "url": "\/post\/remove-document-redirection-vpn\/"
        },
        
        
        
        "\/post\/sync-sharepoint-libraries-powershell\/index\/": {
            
            "title": "Sync SharePoint Libraries with PowerShell",
            "tags": ["PowerShell","Intune",],
            "content": "The Problem So you want to move your files to SharePoint, great! But your users don\u0026rsquo;t understand sharepoint, don\u0026rsquo;t wanna learn sharepoint and just want their file explorer experience.\nThere are a few ways we can go about syncing libraries for our users. We can set a group policy or Intune configuration to automatically sync a SharePoint library however there are some big caveats with this such as a 250~ url character limit. We could also try and provide instructions to have our users sync it themselves or we can remote in and do it for them. But say you just have a few users that need a library. Can we just make a simple PS script to sync the library without going through a GPO? Sure we can!\nLets Automate First, we need to get the sync link. To do that go to the SharePoint document library you want to sync, and fire up your browser developer tools. Go to Network, Select All. Click the Sync button and grab the URL\nNow fire up your favorite script editor.\nWe need to set some variables. First we need to get the users email address. We can do this by looking at the OneDrive for Business registry key.\nThen specify the SharePoint Site Name\n$onedrivepath = \u0026#34;registry::HKCU\\SOFTWARE\\Microsoft\\OneDrive\\Accounts\\Business1\u0026#34; $email = (Get-itemproperty $onedrivepath).useremail $email = $email.replace(\u0026#39;@\u0026#39;,\u0026#39;%40\u0026#39;) $email = $email.replace(\u0026#39;.\u0026#39;, \u0026#39;%2E\u0026#39;) $TenantName = (Get-itemproperty $onedrivepath).displayname $ODParentFolder = (get-itemproperty $onedrivepath).userfolder | split-path $site = #Name of Sharpoint Site Next, take the URL you copied earlier. Remove the string starting after sync? up to \u0026amp;siteid. Replace with userEmail=$email store as $URL variable. It should look like this when you are done\n$url = \u0026#34;odopen://sync?userEmail=$email\u0026amp;siteId=%7Bae1e23cf%2Ddf19%2D4812%2D9950%2Debb6df6c782e%7D\u0026amp;webId=%7B60c35ac0%2Db7e0%2D40ae%2D8a4f%2D31cf7f0aea48%7D\u0026amp;webTitle=Carol%20Barnes%20Memorial\u0026amp;webTemplate=64\u0026amp;webLogoUrl=%2Fsites%2FCarolBarnesMemorial%2F%5Fapi%2FGroupService%2FGetGroupImage%3Fid%3D%276bd4e65d%2D3445%2D4738%2Dac3f%2Df18836d977a5%27%26hash%3D637528692054184638\u0026amp;webUrl=https%3A%2F%2Fjustgeeks%2Esharepoint%2Ecom%2Fsites%2FCarolBarnesMemorial\u0026amp;onPrem=0\u0026amp;libraryType=3\u0026amp;listId=%7BF024B7B4%2DD3AA%2D422E%2D85B8%2DC3FE2AEA9F02%7D\u0026amp;listTitle=Documents\u0026amp;scope=OPENLIST\u0026#34; Last lets just add a little logic to prevent adding the document library if it is already synced.\n$TestSyncedLibrary = GCI $ODParentFolder\\$tenantname -directory | where name -like \u0026#34;$site*\u0026#34; if ($TestSyncedLibrary.Count -lt 1) { Start-Process $url } Now just upload the script to Intune and set to run as user, or use your favorite RMM tool. You could also deploy this with a login script or use a scheduled task to run at user login.\nJust a shell of an idea.\n", 
            "url": "\/post\/sync-sharepoint-libraries-powershell\/index\/"
        },
        
        
        
        "\/post\/intune-keep-apps-updated-with-winget-and-proactive-remediations\/": {
            
            "title": "",
            "tags": [],
            "content": "", 
            "url": "\/post\/intune-keep-apps-updated-with-winget-and-proactive-remediations\/"
        },
        
        
        
        "\/categories\/": {
            
            "title": "Categories",
            "tags": [],
            "content": "", 
            "url": "\/categories\/"
        },
        
        
        
        "\/search\/": {
            
            "title": "Search me!",
            "tags": [],
            "content": "", 
            "url": "\/search\/"
        },
        
    }
    </script>
    
    <script src="/js/lunr.js"></script>
    <script src="/js/search.js"></script>


      
    </div>

    
      
<script async src="https://www.googletagmanager.com/gtag/js?id=G-WELHH4HTZ7"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WELHH4HTZ7', { 'anonymize_ip': false });
}
</script>

    
  </body>
</html>
